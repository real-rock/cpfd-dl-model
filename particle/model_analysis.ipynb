{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../../codes/scripts/particles/')\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler as dh\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "inputs = [\n",
    "    'PM1_2.5_OUT',\n",
    "    'PM1_2.5_H_OUT',\n",
    "    'PM2.5_OUT',\n",
    "    'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT',\n",
    "    'PM2.5_10_H_OUT',\n",
    "    'PERSON_NUMBER',\n",
    "    'AIR_PURIFIER',\n",
    "    'WINDOW',\n",
    "    'AIR_CONDITIONER',\n",
    "    'DOOR',\n",
    "    'WIND_DEG',\n",
    "    'HUMIDITY'\n",
    "]\n",
    "\n",
    "model_dir = '../../projects/particle/model'\n",
    "model_name = 'conv_20'\n",
    "model_path = model_dir + '/' + model_name\n",
    "\n",
    "config_path = model_path + \"/config.json\"\n",
    "f = open(config_path, \"r\")\n",
    "config = json.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_time_step = config[\"model\"][\"window_size\"]\n",
    "out_time_step = 1\n",
    "offset = config[\"model\"][\"offset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv(f'{model_dir}/{model_name}/result/predict/predict.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "metric_dfs = []\n",
    "for label in ['pm1', 'pm2.5', 'pm10']:\n",
    "    metric_dfs.append(pd.read_csv(f'{model_dir}/{model_name}/result/metric/result_{label}.csv', index_col='Metric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_df(_df, cond_in):\n",
    "    cond_cols = ['PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR']\n",
    "    cond_df = _df.copy()\n",
    "    if len(cond_in) != 5:\n",
    "        print('[ERROR] Invalid condition length')\n",
    "        raise Exception('Invalid condition length')\n",
    "    if cond_in[0] == '0':\n",
    "        cond_df = cond_df[cond_df[cond_cols[0]] == 0]\n",
    "    elif cond_in[1] == '1':\n",
    "        cond_df = cond_df[cond_df[cond_cols[0]] != 0]\n",
    "    for i in range(1, 5, 1):\n",
    "        if cond_in[i] == 'x' or cond_in[i] == 'X':\n",
    "            continue\n",
    "        cond_df = cond_df[cond_df[cond_cols[i]] == int(cond_in[i])]\n",
    "    return cond_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(get_cond_df(pred_df, '00000'), ['PM1', 'PM2.5', 'PM10', 'PM1_PRED', 'PM2.5_PRED', 'PM10_PRED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_cond_df(pred_df, '00000')\n",
    "train_df = df[df['TYPE'] == 'train'].copy()\n",
    "val_df = df[df['TYPE'] == 'val'].copy()\n",
    "test_df = df[df['TYPE'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pms = ['PM1', 'PM2.5', 'PM10']\n",
    "\n",
    "for pm in pms:\n",
    "    print(metrics.calc_r2(test_df[pm].values, test_df[pm + '_PRED'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(test_df, pms + [x + '_PRED' for x in pms])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_pm1_df = pd.read_csv('projects/particle/ode/pm1_pred.csv', index_col='DATE', parse_dates=True)\n",
    "ode_pm25_df = pd.read_csv('projects/particle/ode/pm2.5_pred.csv', index_col='DATE', parse_dates=True)\n",
    "ode_pm10_df = pd.read_csv('projects/particle/ode/pm10_pred.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "ode_pred_df = pd.concat([ode_pm1_df['PM1_PRED'], ode_pm25_df['PM2.5_PRED'], ode_pm10_df['PM10_PRED']], axis=1)\n",
    "ode_pred_df.columns = ['ODE_PM1_PRED', 'ODE_PM2.5_PRED', 'ODE_PM10_PRED']\n",
    "\n",
    "df = pd.concat([pred_df, ode_pred_df], axis=1)\n",
    "\n",
    "pm1_df = df[['PM1', 'PM1_PRED', 'ODE_PM1_PRED']].dropna()\n",
    "pm25_df = df[['PM2.5', 'PM2.5_PRED', 'ODE_PM2.5_PRED']].dropna()\n",
    "pm10_df = df[['PM10', 'PM10_PRED', 'ODE_PM10_PRED']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df[df['TYPE'] == 'test'].dropna()\n",
    "tt.describe()[inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(pm1_df, list(pm1_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(pm25_df, pm25_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(pm10_df, pm10_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.calc_r2(pm1_df['PM1_PRED'].values, pm1_df['ODE_PM1_PRED'].values))\n",
    "print(metrics.calc_r2(pm25_df['PM2.5_PRED'].values, pm25_df['ODE_PM2.5_PRED'].values))\n",
    "print(metrics.calc_r2(pm10_df['PM10_PRED'].values, pm10_df['ODE_PM10_PRED'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시나리오 분석\n",
    "Cond 00000: No event\n",
    "\n",
    "1. 각 $PM$에 높낮이에 따른 $p',\\,k'$값 분석\n",
    "2. Steady state 가정 후 DL model의 output을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = load_model(f'{model_path}/result/model/{model_name}.h5')\n",
    "    meta_df = pd.read_csv(model_path + '/meta.csv', index_col='component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def catch_dates(_df, min_length=in_time_step):\n",
    "    dates = {\"start\": [], \"end\": []}\n",
    "\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    cnt = 0\n",
    "    for idx, row in _df.iterrows():\n",
    "        if np.isnan(row['PM2.5']) or np.isnan(row['PM2.5_H_OUT']) or np.isnan(row['PM2.5_OUT']):\n",
    "            if start_date is not None and end_date is not None and cnt >= min_length:\n",
    "                dates[\"start\"].append(start_date)\n",
    "                dates[\"end\"].append(end_date)\n",
    "            start_date = None\n",
    "            end_date = None\n",
    "            cnt = 0\n",
    "        else:\n",
    "            if start_date is None:\n",
    "                start_date = idx\n",
    "            end_date = idx\n",
    "            cnt += 1\n",
    "    if start_date is not None and end_date is not None:\n",
    "        dates[\"start\"].append(start_date)\n",
    "        dates[\"end\"].append(end_date)\n",
    "    return pd.DataFrame(dates)\n",
    "\n",
    "def to_dataset(_df):\n",
    "    return dh.dfs_to_dataset([_df], meta_df, inputs, outputs, in_time_step=in_time_step, out_time_step=out_time_step, offset=offset, excludes=outputs+['PM1_PRED', 'PM2.5_PRED',\n",
    "       'PM10_PRED', 'TYPE'])\n",
    "\n",
    "def get_dfs(_df):\n",
    "    cp_df = _df.copy()\n",
    "    _dates = catch_dates(cp_df.resample('1T').mean())\n",
    "    \n",
    "    _dfs = []\n",
    "    for i in range(_dates.shape[0]):\n",
    "        _dfs.append(cp_df.loc[_dates['start'][i] : _dates['end'][i]])\n",
    "\n",
    "    return _dfs\n",
    "\n",
    "def get_train_test_dfs(_df, train_date='2022-07-07 13:45'):\n",
    "    _train_df = _df.loc[:pd.to_datetime(train_date)].copy()\n",
    "    _test_df = _df.loc[pd.to_datetime(train_date) + timedelta(minutes=1):].copy()\n",
    "    \n",
    "    _train_dfs = get_dfs(_train_df)\n",
    "    _test_dfs = get_dfs(_test_df)\n",
    "        \n",
    "    return _train_dfs, _test_dfs\n",
    "\n",
    "def get_predict_data(_dfs):\n",
    "    res_dfs = []\n",
    "\n",
    "    for td in _dfs:\n",
    "        df_cp = td.copy()\n",
    "        X, y = to_dataset(df_cp)\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            yhat = model.predict(X, verbose=0)\n",
    "        df_cp = df_cp.iloc[in_time_step + out_time_step + offset - 1:]\n",
    "        for idx, output in enumerate(outputs):\n",
    "            df_cp[output + '_ORG'] = df_cp[output + '_PRED']\n",
    "            df_cp[output] = yhat[:, idx]\n",
    "        res_dfs.append(df_cp)\n",
    "    return res_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, test_dfs = get_train_test_dfs(df)\n",
    "\n",
    "train_de_df = get_predict_data(train_dfs)\n",
    "test_de_df = get_predict_data(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = df.copy()\n",
    "\n",
    "delta = np.random.normal(loc=5, scale=2, size=len(t_df))\n",
    "\n",
    "t_df['PM1_OUT'] = np.maximum(t_df['PM1_OUT'] + delta, 0)\n",
    "t_df['PM2.5_OUT'] = np.maximum(t_df['PM2.5_OUT'] + delta, 0)\n",
    "t_df['PM10_OUT'] = np.maximum(t_df['PM10_OUT'] + delta, 0)\n",
    "\n",
    "h_delta = delta * 0.68195107\n",
    "t_df['PM1_H_OUT'] = np.maximum(t_df['PM1_H_OUT'] + h_delta, 0)\n",
    "t_df['PM2.5_H_OUT'] = np.maximum(t_df['PM2.5_H_OUT'] + h_delta, 0)\n",
    "t_df['PM10_H_OUT'] = np.maximum(t_df['PM10_H_OUT'] + h_delta, 0)\n",
    "\n",
    "train_dfs, test_dfs = get_train_test_dfs(t_df)\n",
    "\n",
    "train_de_df = get_predict_data(train_dfs)\n",
    "test_de_df = get_predict_data(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(par, _df, _target):\n",
    "    p1 = par[0]\n",
    "    p2 = par[1]\n",
    "    k = par[2]\n",
    "\n",
    "    idx_out = _target + '_OUT'\n",
    "    idx_h = _target + '_H_OUT'\n",
    "    pred = np.zeros(_df.shape[0])\n",
    "    pred[0] = _df[_target].iloc[0]\n",
    "\n",
    "    for i in range(0, _df.shape[0] - 1):\n",
    "        delt = (_df.index[i + 1] - _df.index[i]).total_seconds() / 3600.0\n",
    "        pred[i + 1] = pred[i] + delt * (p1 * (_df[idx_out].iloc[i + 1] + _df[idx_out].iloc[i]) / 2 + \n",
    "                                        p2 * (_df[idx_h].iloc[i + 1] + _df[idx_h].iloc[i]) / 2 - k * pred[i] / 2)\n",
    "        pred[i + 1] /= (1 + k / 2)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def predict_without_hall(par, _df, _target):\n",
    "    p1 = par[0]\n",
    "    k = par[1]\n",
    "\n",
    "    idx_out = _target + '_OUT'\n",
    "    pred = np.zeros(_df.shape[0])\n",
    "    pred[0] = _df[_target].iloc[0]\n",
    "\n",
    "    for i in range(0, _df.shape[0] - 1):\n",
    "        delt = (_df.index[i + 1] - _df.index[i]).total_seconds() / 3600.0\n",
    "        pred[i + 1] = pred[i] + delt * (p1 * (_df[idx_out].iloc[i + 1] + _df[idx_out].iloc[i]) / 2)\n",
    "        pred[i + 1] = pred[i + 1] / (1 + k / 2)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def loss_func(par, _dfs, _target):\n",
    "    _meas_res = []\n",
    "    _pred_res = []\n",
    "\n",
    "    predictor = None\n",
    "    if len(par) == 3:\n",
    "        predictor = predict\n",
    "    else:\n",
    "        predictor = predict_without_hall\n",
    "\n",
    "    for _df in _dfs:\n",
    "        _pred_res.append(predictor(par, _df, _target))\n",
    "        _meas_res.append(_df[_target].values)\n",
    "\n",
    "    _meas = np.concatenate(_meas_res, axis=None)\n",
    "    _pred = np.concatenate(_pred_res, axis=None)\n",
    "\n",
    "    return np.var(_meas - _pred)\n",
    "\n",
    "def get_results(par, _dfs, _target):\n",
    "    _res_dfs = []\n",
    "\n",
    "    if len(par) == 3:\n",
    "        predictor = predict\n",
    "    else:\n",
    "        predictor = predict_without_hall\n",
    "\n",
    "    for i, _df in enumerate(_dfs):\n",
    "        pred_res = predictor(par, _df)\n",
    "        _df[_target + '_PRED'] = pred_res\n",
    "\n",
    "        _res_dfs.append(_df.copy())\n",
    "\n",
    "    return pd.concat(_res_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "\n",
    "w = [0.71440267, 0.68195107, 0.6384208]\n",
    "pms = ['pm1', 'pm2.5', 'pm10']\n",
    "delta_means = [5, -5, 10, -10, 15, -15]\n",
    "\n",
    "n_iter = 100\n",
    "res_data = np.zeros((n_iter, 2))\n",
    "\n",
    "for p_idx, pm in enumerate(pms):\n",
    "    for dm in delta_means:\n",
    "        for i in range(0, n_iter):\n",
    "            t_df = df.copy()\n",
    "\n",
    "            delta = np.random.normal(loc=dm, scale=2, size=len(t_df))\n",
    "\n",
    "            t_df['PM1_OUT'] = np.maximum(t_df['PM1_OUT'] + delta, 0)\n",
    "            t_df['PM2.5_OUT'] = np.maximum(t_df['PM2.5_OUT'] + delta, 0)\n",
    "            t_df['PM10_OUT'] = np.maximum(t_df['PM10_OUT'] + delta, 0)\n",
    "\n",
    "            t_df['PM1_H_OUT'] = np.maximum(t_df['PM1_H_OUT'] + delta * w[0], 0)\n",
    "            t_df['PM2.5_H_OUT'] = np.maximum(t_df['PM2.5_H_OUT'] + delta * w[1], 0)\n",
    "            t_df['PM10_H_OUT'] = np.maximum(t_df['PM10_H_OUT'] + delta * w[2], 0)\n",
    "\n",
    "            train_dfs, test_dfs = get_train_test_dfs(t_df)\n",
    "\n",
    "            train_de_df = get_predict_data(train_dfs)\n",
    "            test_de_df = get_predict_data(test_dfs)\n",
    "            bounds = [(0, 2)] * 2\n",
    "\n",
    "            results = op.shgo(lambda x, y=train_de_df, z=pm.upper(): loss_func(x, y, z), bounds=bounds)\n",
    "            res_data[i] = results.x.tolist()\n",
    "\n",
    "        np.save(f'../../projects/particle/pk/{pm}_{dm:02d}_pk_res.npy', res_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pms = ['pm1', 'pm2.5', 'pm10']\n",
    "delta_means = [5, -5, 10, -10, 15, -15]\n",
    "dfs = []\n",
    "\n",
    "for p_idx, pm in enumerate(pms):\n",
    "    data = []\n",
    "    for dm in delta_means:\n",
    "        d = np.load(f'../../projects/particle/pk/{pm}_{dm:02d}_pk_res.npy')\n",
    "        data.append(d)\n",
    "    cols = [f'{pm}_{x}_p' if i % 2 == 0 else f'{pm}_{x}_k' for i, x in enumerate([5, 5, -5, -5, 10, 10, -10, -10, 15, 15, -15, -15])]\n",
    "\n",
    "    dfs.append(pd.DataFrame(np.concatenate(data, axis=1), columns=cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_hist(_dfs):\n",
    "    fig, axes = plt.subplots(3, figsize=(22, 10))\n",
    "    for i, _df in enumerate(_dfs):\n",
    "        _df[_df.columns[0::2]].plot(kind='hist', bins=100, ax=axes[i])\n",
    "    fig.suptitle('''$p'$ distribution''', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_p_hist(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pk_df.plot(kind='hist', y=['pm1_p', 'pm25_p', 'pm10_p'], bins=15, figsize=(22, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "bounds = [(0, 2)] * 2\n",
    "\n",
    "results = op.shgo(lambda x, y=train_de_df: loss_func(x, y), bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = get_results(results.x.tolist(), train_de_df).dropna()\n",
    "test_res = get_results(results.x.tolist(), test_de_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = get_results([0.201964166, 0.014322877], test_de_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(train_res, [target, target + '_PRED', target + '_ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(test_res, [target, target + '_PRED', target + '_ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_r2(test_res[target].values, test_res[target + '_PRED'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_r2(train_res[target].values, train_res[target + '_PRED'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_corrcoef(test_res[target].values, test_res[target + '_PRED'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_fb(test_res[target].values, test_res[target + '_PRED'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(df['PM10_OUT'].values.reshape(-1, 1), df['PM10_H_OUT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(df['PM10_OUT'].values.reshape(-1, 1), df['PM10_H_OUT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'coef: {reg.coef_}, bias: {reg.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4088fd0d3796640b1c65f1ddd822ba54c2009473962059d86be4eae2585c4d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
