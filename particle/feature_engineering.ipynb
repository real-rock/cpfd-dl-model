{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf37aa-01b5-4514-bd77-e1f797a8d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "\n",
    "sys.path.append(\"./scripts/particles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27b805-091e-4137-a736-b2c96cc2b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler as dh\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ffcb9-6c58-4775-a815-fb24aeec7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "features = [\n",
    "    'PM1_2.5_OUT', 'PM1_2.5_H_OUT', \n",
    "    'PM2.5_OUT', 'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT', 'PM2.5_10_H_OUT',\n",
    "    'PERSON_NUMBER', 'AIR_PURIFIER', 'WINDOW', 'AIR_CONDITIONER',\n",
    "    'DOOR', 'WIND_SPEED', 'WIND_DEG', 'HUMIDITY'\n",
    "]\n",
    "\n",
    "dates = [\n",
    "    {\"start\": \"2022-05-07 09:40\", \"end\": \"2022-05-17 08:38\"},\n",
    "    {\"start\": \"2022-05-17 11:25\", \"end\": \"2022-05-30 23:26\"},\n",
    "    {\"start\": \"2022-06-01 22:40\", \"end\": \"2022-07-02 07:00\"},\n",
    "    {\"start\": \"2022-07-02 16:40\", \"end\": \"2022-07-09 07:13\"},\n",
    "    {\"start\": \"2022-07-09 14:30\", \"end\": \"2022-07-12 10:00\"},\n",
    "    {\"start\": \"2022-07-25 12:00\", \"end\": \"2022-08-01 10:00\"},\n",
    "    {\"start\": \"2022-08-03 09:00\", \"end\": \"2022-08-11 22:18\"},\n",
    "    {\"start\": \"2022-08-12 12:14\", \"end\": \"2022-08-20 00:00\"},\n",
    "    {\"start\": \"2022-08-20 09:38\", \"end\": \"2022-09-01 00:00\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a4331-0975-421f-9f39-7b6e5ab353e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df = pd.read_csv('../storage/particle/weather.csv', index_col='DATE', parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "# weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180)\n",
    "\n",
    "# df_org = dh.load_data(\"../storage/particle/data.csv\")\n",
    "# df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "# df = pd.concat([df_org, weather_df], axis=1)\n",
    "# df = df[(df.index >= pd.to_datetime('2022-05-07 09:40')) & (df.index <= pd.to_datetime('2022-09-01 00:00'))]\n",
    "\n",
    "df = pd.read_csv('../storage/particle/data_for_analysis.csv', index_col='DATE', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc01e3-4c22-4d32-b6a4-14348591bd82",
   "metadata": {},
   "source": [
    "# 1. Feature correlation\n",
    "- Pearson correlation(linear)\n",
    "    - $\\rho_{xy}=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}},\\;where\\,\\bar{x}=\\frac{1}{n}\\sum_{i=1}^nx_i,\\,\\bar{y}=\\frac{1}{n}\\sum_{i=1}^ny_i$\n",
    "- Spearman's rank-based correlation(non-linear)\n",
    "    - $\\sigma_{xy}=1-\\frac{6\\sum_{i=1}^nd_i^2}{n(n^2-1)},\\;where\\, d_i:=|rank(x_i)-rank(y_i)|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7c3fc-9500-435f-8510-9e66f590be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_df = df.dropna()\n",
    "p_res = np.zeros((len(features), len(outputs))) # pearson corr\n",
    "s_res = np.zeros((len(features), len(outputs))) # spearman corr\n",
    "\n",
    "for o_idx, output in enumerate(outputs):\n",
    "    out_data = cp_df[output].values\n",
    "    for f_idx, feature in enumerate(features):\n",
    "        feat_data = cp_df[feature].values\n",
    "        p_corr = np.corrcoef(out_data, feat_data)\n",
    "        p_res[f_idx, o_idx] = p_corr[0, 1]\n",
    "        s_corr = stats.spearmanr(out_data, feat_data)\n",
    "        s_res[f_idx, o_idx] = s_corr.correlation\n",
    "\n",
    "corr_df = pd.DataFrame(p_res, index=features, columns=outputs)\n",
    "scorr_df = pd.DataFrame(s_res, index=features, columns=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f1a6f-7b9f-4a04-86fd-7d244c4519c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idc = abs(corr_df['PM2.5']).sort_values(ascending=False).index\n",
    "ax = corr_df['PM2.5'].loc[sorted_idc].plot(kind='bar', figsize=(18, 10))\n",
    "ax.set_ylabel('Pearson correlation', fontsize=17)\n",
    "ax.set_xlabel('Feature', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ec007-4a23-437a-b0cd-0723ce93648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idc = abs(scorr_df['PM2.5']).sort_values(ascending=False).index\n",
    "ax = scorr_df['PM2.5'].loc[sorted_idc].plot(kind='bar', figsize=(18, 10))\n",
    "ax.set_ylabel('Pearson correlation', fontsize=17)\n",
    "ax.set_xlabel('Feature', fontsize=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b52cd-0067-4881-9dec-cf688e5a7926",
   "metadata": {},
   "source": [
    "# 2. Permutation importance\n",
    "1. Load model\n",
    "2. Get mse with original data\n",
    "3. Get mse with permutated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4fd7a-3334-4ea5-96d2-b250f0214216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "inputs = [\n",
    "    'PM1_2.5_OUT',\n",
    "    'PM1_2.5_H_OUT',\n",
    "    'PM2.5_OUT',\n",
    "    'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT',\n",
    "    'PM2.5_10_H_OUT', # 3\n",
    "    'PERSON_NUMBER',\n",
    "    'AIR_PURIFIER',\n",
    "    'WINDOW',\n",
    "    'AIR_CONDITIONER',\n",
    "    'DOOR', # 4\n",
    "    'TEMPERATURE', # 1\n",
    "    # 'WIND_SPEED', # 2\n",
    "    'WIND_DEG',\n",
    "    'HUMIDITY'\n",
    "]\n",
    "\n",
    "model_struct = 'gru'\n",
    "model_num = 3\n",
    "\n",
    "f = open(f'../projects/particle/model/{model_struct}_{model_num:02d}/config.json', 'r')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "moving_average_window = config[\"data\"][\"moving_average_window\"]\n",
    "moving_average_method = config[\"data\"][\"moving_average_method\"]\n",
    "val_size = config[\"data\"][\"validation\"]\n",
    "test_size = config[\"data\"][\"test\"]\n",
    "train_size = 1 - val_size - test_size\n",
    "dates = config[\"data\"][\"dates\"]\n",
    "\n",
    "in_time_step = config[\"model\"][\"window_size\"]\n",
    "out_time_step = 1\n",
    "offset = config[\"model\"][\"offset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1f0b3-6c87-4c26-bb4a-a289a47b32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../storage/particle/weather.csv', index_col='DATE', parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180)\n",
    "\n",
    "df_org = dh.load_data(\"../storage/particle/data.csv\")\n",
    "df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "excludes = ['PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR']\n",
    "df = dh.apply_moving_average(pd.concat([df_org, weather_df], axis=1), \n",
    "                             window=moving_average_window, \n",
    "                             method=moving_average_method, \n",
    "                             excludes=excludes, \n",
    "                             min_periods=1)\n",
    "df = pd.concat([df, df_org[excludes]], axis=1)\n",
    "df[excludes] = df[excludes].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = dh.trim_df(df, dates)\n",
    "\n",
    "train_dfs, val_dfs, test_dfs = dh.train_test_split_df(dfs, val_size, test_size)\n",
    "meta_df = pd.concat(train_dfs).describe()\n",
    "\n",
    "def to_dataset(_dfs, in_time_step):\n",
    "    return dh.dfs_to_dataset(_dfs, meta_df, inputs, outputs, in_time_step=in_time_step, out_time_step=1, offset=1, excludes=outputs)\n",
    "\n",
    "win_size = config[\"model\"][\"window_size\"]\n",
    "X_train, y_train = to_dataset(train_dfs, win_size)\n",
    "X_val, y_val = to_dataset(val_dfs, win_size)\n",
    "X_test, y_test = to_dataset(test_dfs, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23cf4b-b8f3-445e-b047-370f3afe98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(f'../projects/particle/model/{model_struct}_{model_num:02d}/result/model/{model_struct}_{model_num:02d}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43043f1-9581-476e-814c-bd762424af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(_dfs, output_scaled=False):\n",
    "    res_dfs = []\n",
    "    for _df in _dfs:\n",
    "        df_cp = _df.copy()\n",
    "        _X, _y = dh.dfs_to_dataset([df_cp], meta_df, inputs, outputs, in_time_step=in_time_step)\n",
    "        y_hat = model.predict(_X, verbose=False)\n",
    "        df_cp = df_cp.iloc[in_time_step + out_time_step + offset - 1:]\n",
    "        for idx, output in enumerate(outputs):\n",
    "            if output_scaled:\n",
    "                min_val = meta_df[output]['min']\n",
    "                max_val = meta_df[output]['max']\n",
    "                df_cp[output + '_PRED'] = y_hat[:, idx] * (max_val - min_val) + min_val\n",
    "            else:\n",
    "                df_cp[output + '_PRED'] = y_hat[:, idx]\n",
    "        res_dfs.append(df_cp)\n",
    "    return pd.concat(res_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935ae8a-18c2-4828-bc60-ef1a418ab068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = get_result(train_dfs)\n",
    "train_res['TYPE'] = 'train'\n",
    "val_res = get_result(val_dfs)\n",
    "val_res['TYPE'] = 'val'\n",
    "test_res = get_result(test_dfs)\n",
    "test_res['TYPE'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8658d-8581-4143-963e-de0a5a14f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"pm1\", \"pm2.5\", \"pm10\"]\n",
    "total_res = pd.concat([train_res, val_res, test_res])\n",
    "res_dfs = [total_res, train_res, val_res, test_res]\n",
    "res_indices = [\"Total\", \"Train\", \"Validation\", \"Test\"]\n",
    "metric_funcs = [metrics.calc_r2, metrics.calc_corrcoef, metrics.calc_nmse, metrics.calc_fb, metrics.calc_b, metrics.calc_a_co, metrics.calc_rmse]\n",
    "metrics_indices = [\"R Square\", \"Corr\", \"NMSE\", \"FB\", \"B\", \"a/C\", 'rmse']\n",
    "\n",
    "\n",
    "def calc_metric(_f, _df, _col):\n",
    "    return _f(_df[_col].values, _df[_col + \"_PRED\"].values)\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"======== {col} prediction results ========\")\n",
    "    res_dict = {\n",
    "        \"Metric\": metrics_indices,\n",
    "        \"Total\": [],\n",
    "        \"Train\": [],\n",
    "        \"Validation\": [],\n",
    "        \"Test\": [],\n",
    "    }\n",
    "\n",
    "    for j, m in enumerate(metric_funcs):\n",
    "        for i, rd in enumerate(res_dfs):\n",
    "            s = calc_metric(m, rd, col.upper())\n",
    "            res_dict[res_indices[i]].append(s)\n",
    "\n",
    "    r_df = pd.DataFrame(res_dict)\n",
    "    print(r_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69976c-ed24-4117-b0d5-3c414e709de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "mse_data = np.zeros((len(inputs) + 1, len(outputs)))\n",
    "\n",
    "for o_idx, o in enumerate(outputs):\n",
    "    mse_data[0, o_idx] = metrics.calc_mse(test_res[o].values, test_res[o+'_PRED'].values)\n",
    "\n",
    "for f_idx, feat in enumerate(inputs):\n",
    "    print(f'[INFO] Feature name `{feat}` starts')\n",
    "    cp_df = df.copy()\n",
    "    cp_df[feat] = np.random.permutation(cp_df[feat].values)\n",
    "    p_dfs = dh.trim_df(cp_df, dates)\n",
    "\n",
    "    train_dfs, val_dfs, test_dfs = dh.train_test_split_df(p_dfs, val_size, test_size)\n",
    "    X, y = to_dataset(test_dfs, win_size)\n",
    "    y_hat = model.predict(X)\n",
    "    for o_idx, o in enumerate(outputs):\n",
    "        mse_data[f_idx + 1, o_idx] = metrics.calc_mse(y[:, 0, o_idx], y_hat[:, o_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e402e-311e-4e84-b070-f9653eabf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_df = pd.DataFrame(mse_data, index=['Base']+inputs, columns=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2a36e-19c9-471a-b918-1c20706ace37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_df.to_csv('fi_gru_without_ws.csv', index_label='FEATURE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8a1f1-f07c-49fe-b70b-3d41570b6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat_idx in mse_df.index:\n",
    "    for o in outputs:\n",
    "        mse_df.loc[feat_idx, o + '_DIFF'] = mse_df.loc[feat_idx, o] - mse_df.loc['Base', o]\n",
    "        mse_df.loc[feat_idx, o + '_INC'] = (mse_df.loc[feat_idx, o + '_DIFF']) / mse_df.loc['Base', o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e505f5d-25bd-4ecb-bbe8-36df9a92b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c0368-067a-4f95-b37e-e142e061ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(mse_df_in, title):\n",
    "    sorted_df = mse_df_in[['PM1_INC', 'PM2.5_INC', 'PM10_INC']].copy()\n",
    "    sorted_df['sum'] = sorted_df.sum(axis=1).values\n",
    "    sorted_df = sorted_df.sort_values(by='sum', ascending=False)\n",
    "    sorted_df = sorted_df[['PM1_INC', 'PM2.5_INC', 'PM10_INC']]\n",
    "    sorted_df = sorted_df * 100\n",
    "    ax = sorted_df.plot(kind='bar', figsize=(18, 10))\n",
    "    ax.set_ylabel('Prediction Error(%)', fontsize=17)\n",
    "    ax.set_xlabel('Feature', fontsize=17)\n",
    "    ax.set_title(title, fontsize=22)\n",
    "    ax.set_xticklabels(labels=sorted_df.index, rotation=45)\n",
    "    ax.legend(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e595fc-f5c5-40ae-8c98-62ffcb67bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_df, 'FI without wind speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1ca1b-f123-45b9-915a-fbb60d990d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_df = pd.read_csv('fi_with_whole_features.csv', index_col='FEATURE')\n",
    "plot_mse(mse_df, 'FI with whole features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8b7d4-42d0-427c-99c0-82982f4737c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.set_title('Feature Importance without temperature, wind speed, pm2.5~10 hall out, door', fontsize=22)\n",
    "mse_df = pd.read_csv('fi_without_temp.csv', index_col='FEATURE')\n",
    "# plot_mse(mse_df, 'FI without T')\n",
    "plot_mse(mse_df.drop('WINDOW'), 'FI without T (Except window)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978969f-5890-44cb-8bce-ce64648ee910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.set_title('Feature Importance without temperature, wind speed, pm2.5~10 hall out, door', fontsize=22)\n",
    "mse_df = pd.read_csv('fi_without_temp,ws.csv', index_col='FEATURE')\n",
    "# plot_mse(mse_df, 'FI without T, WS')\n",
    "plot_mse(mse_df.drop('WINDOW'), 'FI without T, WS (Except window)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e58cd9-c498-4840-b653-b2c2b5965a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax.set_title('Feature Importance without temperature, wind speed, pm2.5~10 hall out, door', fontsize=22)\n",
    "mse_df = pd.read_csv('fi_without_temp,ws,pm25_10_h_out.csv', index_col='FEATURE')\n",
    "# plot_mse(mse_df, 'FI without T, WS, PM2.5-10 hall out')\n",
    "plot_mse(mse_df.drop('WINDOW'), 'FI without T, WS, PM2.5-10 hall out (Except window)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef876c2a-7368-4ced-8066-22a03dd5d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.set_title('Feature Importance without temperature, wind speed, pm2.5~10 hall out, door', fontsize=22)\n",
    "mse_df = pd.read_csv('fi_without_temp,ws,pm25_10_h_out,door.csv', index_col='FEATURE')\n",
    "plot_mse(mse_df, 'FI without T, WS, PM2.5-10 hall out, D')\n",
    "# plot_mse(mse_df.drop('WINDOW'), 'FI without T, WS, PM2.5-10 hall out, D (Except window)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d71df6-563c-47af-95d4-66bf975c52a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
