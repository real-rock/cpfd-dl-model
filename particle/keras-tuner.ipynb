{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"./scripts/particles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler as dh\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "inputs = [\n",
    "    'PM1_2.5_OUT',\n",
    "    'PM1_2.5_H_OUT',\n",
    "    'PM2.5_OUT',\n",
    "    'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT',\n",
    "    'PM2.5_10_H_OUT',\n",
    "    'PERSON_NUMBER',\n",
    "    'AIR_PURIFIER',\n",
    "    'WINDOW',\n",
    "    'AIR_CONDITIONER',\n",
    "    'DOOR',\n",
    "    'WIND_DEG',\n",
    "    'HUMIDITY'\n",
    "]\n",
    "\n",
    "offset = 1\n",
    "out_time_step = 1\n",
    "\n",
    "dates = [\n",
    "    {\"start\": \"2022-05-07 09:40\", \"end\": \"2022-05-17 08:38\"},\n",
    "    {\"start\": \"2022-05-17 11:25\", \"end\": \"2022-05-30 23:26\"},\n",
    "    {\"start\": \"2022-06-01 22:40\", \"end\": \"2022-07-02 07:00\"},\n",
    "    {\"start\": \"2022-07-02 16:40\", \"end\": \"2022-07-09 07:13\"},\n",
    "    {\"start\": \"2022-07-09 14:30\", \"end\": \"2022-07-12 10:00\"},\n",
    "    {\"start\": \"2022-07-25 12:00\", \"end\": \"2022-08-01 10:00\"},\n",
    "    {\"start\": \"2022-08-03 09:00\", \"end\": \"2022-08-11 22:18\"},\n",
    "    {\"start\": \"2022-08-12 12:14\", \"end\": \"2022-08-20 00:00\"},\n",
    "    {\"start\": \"2022-08-20 09:38\", \"end\": \"2022-09-01 00:00\"},\n",
    "]\n",
    "\n",
    "moving_average_window = 20\n",
    "moving_average_method = 'mean'\n",
    "val_size = 0.15\n",
    "test_size = 0.25\n",
    "train_size = 1 - val_size - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../storage/particle/weather.csv', index_col='DATE', parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180)\n",
    "\n",
    "df_org = dh.load_data(\"../storage/particle/data.csv\")\n",
    "df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "excludes = ['PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR']\n",
    "df = dh.apply_moving_average(pd.concat([df_org, weather_df], axis=1), \n",
    "                             window=moving_average_window, \n",
    "                             method=moving_average_method, \n",
    "                             excludes=excludes,\n",
    "                             min_periods=1)\n",
    "df = pd.concat([df, df_org[excludes]], axis=1)\n",
    "df[excludes] = df[excludes].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = dh.trim_df(df, dates)\n",
    "train_dfs, val_dfs, test_dfs = dh.train_test_split_df(dfs, val_size, test_size)\n",
    "meta_df = pd.concat(train_dfs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = {}\n",
    "val_ds = {}\n",
    "test_ds = {}\n",
    "\n",
    "win_sizes = [12, 16, 30, 45, 60]\n",
    "\n",
    "def to_dataset(_dfs, in_time_step):\n",
    "    return dh.dfs_to_dataset(_dfs, meta_df, inputs, outputs, in_time_step=in_time_step, out_time_step=out_time_step, offset=offset, excludes=outputs)\n",
    "\n",
    "for win_size in win_sizes:\n",
    "    train_ds[str(win_size)] = to_dataset(train_dfs, win_size)\n",
    "    val_ds[str(win_size)] = to_dataset(val_dfs, win_size)\n",
    "    test_ds[str(win_size)] = to_dataset(test_dfs, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=10, mode=\"min\", min_lr=1e-6, verbose=False\n",
    ")\n",
    "ely_cb = EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\", verbose=False, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D, LSTM, BatchNormalization, LeakyReLU, SimpleRNN, GRU, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "rnn_types = [SimpleRNN, LSTM, GRU]\n",
    "\n",
    "class ConvPredictor(kt.HyperModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.win_size = None\n",
    "        \n",
    "    def build(self, hp):\n",
    "        self.win_size = hp.Choice('window_size', win_sizes, default=win_sizes[0])\n",
    "        n_conv_layers = hp.Choice('n_conv_layers', [0, 1, 2], default=1)\n",
    "        n_rnn_layers = hp.Choice('n_rnn_layers', [0, 1, 2], default=0)\n",
    "        rnn_type = hp.Choice('rnn_type', [0, 1, 2], default=2)\n",
    "        \n",
    "        inputs = train_ds[str(self.win_size)][0]\n",
    "        outputs = train_ds[str(self.win_size)][1]\n",
    "        \n",
    "        input_tensor = Input(shape=(inputs.shape[1], inputs.shape[2]), name='input')\n",
    "        x = input_tensor\n",
    "        \n",
    "        for i in range(n_conv_layers):\n",
    "            x = Conv1D(hp.Int(f'conv_filters_{i}', min_value=16, max_value=128, step=16), \n",
    "                       kernel_size=hp.Int(f'kernel_size_{i}', min_value=3, max_value=5, step=1), \n",
    "                       activation='relu', \n",
    "                       strides=hp.Int(f'conv_strides_{i}', min_value=1, max_value=3, step=1), \n",
    "                       padding='same')(x)\n",
    "\n",
    "        for i in range(n_rnn_layers):\n",
    "            x = rnn_types[rnn_type](\n",
    "                units=hp.Int(f'gru_units_{i}', min_value=32, max_value=256, step=32), \n",
    "                activation='tanh', \n",
    "                kernel_initializer='he_uniform', \n",
    "                return_sequences=True,\n",
    "                dropout=hp.Float(f'gru_dropout_{i}', min_value=0.0, max_value=0.5, step=0.05)\n",
    "            )(x)\n",
    "\n",
    "        pool_size = hp.Int('max_pool_size', min_value=2, max_value=5, step=1)\n",
    "        pool_strides = hp.Choice('max_pool_strides', [0, 1, 2, 3, 4])\n",
    "        if pool_strides == 0:\n",
    "            pool_strides = None\n",
    "        x = MaxPooling1D(pool_size=pool_size, strides=pool_strides)(x)\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        fc_units = hp.Int('fc_units', min_value=32, max_value=256, step=32)\n",
    "        leaky_relu = hp.Float('leaky_relu', min_value=0.0, max_value=0.5, step=0.05)\n",
    "        fc_dropout = hp.Float('fc_dropout', min_value=0.0, max_value=0.5, step=0.05)\n",
    "\n",
    "        x = Dense(fc_units, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=leaky_relu))(x)\n",
    "        x = Dropout(fc_dropout)(x)\n",
    "\n",
    "        output = Dense(outputs.shape[2], kernel_initializer='he_uniform', activation='relu', name='output')(x)\n",
    "\n",
    "        model = Model(inputs=input_tensor, outputs=output, name='model')\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', [0.001, 0.0001, 0.00001])\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=hp_learning_rate), loss='mse', metrics=RootMeanSquaredError()\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            train_ds[str(self.win_size)][0],\n",
    "            train_ds[str(self.win_size)][1],\n",
    "            validation_data=(test_ds[str(self.win_size)][0], test_ds[str(self.win_size)][1]),\n",
    "            *args,\n",
    "            batch_size=hp.Int('batch_size', min_value=32, max_value=256, step=32),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "new_proj = 'conv_02'\n",
    "# exist_proj = 'KTBO_2022-08-21_14:57'\n",
    "\n",
    "proj = new_proj\n",
    "\n",
    "tuner = kt.tuners.BayesianOptimization(\n",
    "    ConvPredictor(),\n",
    "    seed=42,\n",
    "    objective='val_loss',\n",
    "    max_trials=120,\n",
    "    executions_per_trial=3,\n",
    "    directory='../projects/particle/kt/bo',\n",
    "    project_name=proj\n",
    ")\n",
    "\n",
    "tuner.search(epochs=100, shuffle=False, callbacks=[rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "window_size : {best_hp.get('window_size')}\n",
    "conv_filters : {best_hp.get('conv_filters')}\n",
    "conv_strides : {best_hp.get('conv_strides')}\n",
    "kernel_size : {best_hp.get('kernel_size')}\n",
    "pool_size : {best_hp.get('pool_size')}\n",
    "pool_strides : {best_hp.get('pool_strides')}\n",
    "fc_units : {best_hp.get('fc_units')}\n",
    "leaky_relu : {best_hp.get('leaky_relu')}\n",
    "fc_dropout : {best_hp.get('fc_dropout')}\n",
    "learning_rate : {best_hp.get('learning_rate')}\n",
    "batch_size : {best_hp.get('batch_size')}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "print(f'''\n",
    "struct: {best_hp.get('struct')}\n",
    "conv_units_1: {best_hp.get('conv_units_1')}\n",
    "conv_strides_1: {best_hp.get('conv_strides_1')}\n",
    "kernel_size_1: {best_hp.get('kernel_size_1')}\n",
    "conv_units_2: {best_hp.get('conv_units_2')}\n",
    "conv_strides_2: {best_hp.get('conv_strides_2')}\n",
    "kernel_size_2: {best_hp.get('kernel_size_2')}\n",
    "pool_size: {best_hp.get('pool_size')}\n",
    "fc_units: {best_hp.get('fc_units')}\n",
    "leaky_relu: {best_hp.get('leaky_relu')}\n",
    "fc_dropout: {best_hp.get('fc_dropout')}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "struct : {best_hp.get('struct')}\n",
    "conv_units_1 : {best_hp.get('conv_units_1')}\n",
    "kernel_size_1 : {best_hp.get('kernel_size_1')}\n",
    "conv_strides : {best_hp.get('conv_strides')}\n",
    "gru_units_1 : {best_hp.get('gru_units_1')}\n",
    "gru_units_2 : {best_hp.get('gru_units_2')}\n",
    "fc_units : {best_hp.get('fc_units')}\n",
    "leaky_relu : {best_hp.get('leaky_relu')}\n",
    "gru_dropout_1 : {best_hp.get('gru_dropout_1')}\n",
    "gru_dropout_2 : {best_hp.get('gru_dropout_2')}\n",
    "fc_dropout : {best_hp.get('fc_dropout')}\n",
    "learning_rate : {best_hp.get('learning_rate')}\n",
    "batch_size : {best_hp.get('batch_size')}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pred = best_model.predict(X_train)\n",
    "val_pred = best_model.predict(X_val)\n",
    "test_pred = best_model.predict(X_test)\n",
    "\n",
    "pred = np.concatenate((train_pred, val_pred, test_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dd in dfs:\n",
    "    x_ele, y_real = conv_to_dataset(\n",
    "        min_max_scale(\n",
    "            dd, [\n",
    "                'PM2.5_OUT',\n",
    "                'PM2.5_H_OUT',\n",
    "                'PM1_2.5_OUT',\n",
    "                'PM1_2.5_H_OUT',\n",
    "                'PM2.5_10_OUT',\n",
    "                'PM2.5_10_H_OUT',\n",
    "                'PERSON_NUMBER',\n",
    "            ], meta\n",
    "        ), FEATURE_LABEL, TARGET_LABEL, WINDOW_SIZE, OUTPUT_SIZE, OFFSET, verbose=False\n",
    "    )\n",
    "    y_hat = best_model.predict(x_ele, verbose=0)\n",
    "    _tmp_df = dd.iloc[WINDOW_SIZE + OFFSET + 1:].copy()\n",
    "    _tmp_df['PM1_PRED'] = y_hat[:, 0]\n",
    "    _tmp_df['PM2.5_PRED'] = y_hat[:, 1]\n",
    "    _tmp_df['PM10_PRED'] = y_hat[:, 2]\n",
    "    results.append(_tmp_df)\n",
    "\n",
    "res_df = pd.concat(results)\n",
    "ax = res_df[len(X_train):len(X_train) + len(X_val)].plot.scatter(x='PM2.5', y='PM2.5_PRED', c='y', figsize=(15, 15))\n",
    "res_df[len(X_train) + len(X_val):].plot.scatter(x='PM2.5', y='PM2.5_PRED', c='g', figsize=(15, 15), ax=ax)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "\n",
    "ax.plot(lims, lims, 'r-', linewidth=2, alpha=0.75, zorder=2)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_result = pd.DataFrame(\n",
    "    {\n",
    "        'pm1 real': y[:, 0, 0], 'pm2.5 real': y[:, 0, 1], 'pm10 real': y[:, 0, 2], 'pm1 pred': pred[:, 0],\n",
    "        'pm2.5 pred': pred[:, 1], 'pm10 pred': pred[:, 2]\n",
    "    }\n",
    ")\n",
    "train_result = pd.DataFrame(\n",
    "    {\n",
    "        'pm1 real': y_train[:, 0], 'pm2.5 real': y_train[:, 1], 'pm10 real': y_train[:, 2],\n",
    "        'pm1 pred': train_pred[:, 0],\n",
    "        'pm2.5 pred': train_pred[:, 1], 'pm10 pred': train_pred[:, 2]\n",
    "    }\n",
    ")\n",
    "val_result = pd.DataFrame(\n",
    "    {\n",
    "        'pm1 real': y_val[:, 0], 'pm2.5 real': y_val[:, 1], 'pm10 real': y_val[:, 2], 'pm1 pred': val_pred[:, 0],\n",
    "        'pm2.5 pred': val_pred[:, 1], 'pm10 pred': val_pred[:, 2]\n",
    "    }\n",
    ")\n",
    "test_result = pd.DataFrame(\n",
    "    {\n",
    "        'pm1 real': y_test[:, 0], 'pm2.5 real': y_test[:, 1], 'pm10 real': y_test[:, 2], 'pm1 pred': test_pred[:, 0],\n",
    "        'pm2.5 pred': test_pred[:, 1], 'pm10 pred': test_pred[:, 2]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=9, ncols=1, figsize=(26, 40))\n",
    "train_result.plot(kind='line', y=['pm1 real', 'pm1 pred'], ax=axes[0], title='PM1 Training')\n",
    "train_result.plot(kind='line', y=['pm2.5 real', 'pm2.5 pred'], ax=axes[1], title='PM2.5 Training')\n",
    "train_result.plot(kind='line', y=['pm10 real', 'pm10 pred'], ax=axes[2], title='PM10 Training')\n",
    "val_result.plot(kind='line', y=['pm1 real', 'pm1 pred'], ax=axes[3], title='PM1 Validation')\n",
    "val_result.plot(kind='line', y=['pm2.5 real', 'pm2.5 pred'], ax=axes[4], title='PM2.5 Validation')\n",
    "val_result.plot(kind='line', y=['pm10 real', 'pm10 pred'], ax=axes[5], title='PM10 Validation')\n",
    "test_result.plot(kind='line', y=['pm1 real', 'pm1 pred'], ax=axes[6], title='PM1 Testing')\n",
    "test_result.plot(kind='line', y=['pm2.5 real', 'pm2.5 pred'], ax=axes[7], title='PM2.5 Testing')\n",
    "test_result.plot(kind='line', y=['pm10 real', 'pm10 pred'], ax=axes[8], title='PM10 Testing')\n",
    "plt.xlabel('Time [min]', fontsize=13)\n",
    "for i in range(3):\n",
    "    axes[i * 3 + 0].set_ylabel('PM1 [$\\mu g/m^3$]', fontsize=13)\n",
    "    axes[i * 3 + 1].set_ylabel('PM2.5 [$\\mu g/m^3$]', fontsize=13)\n",
    "    axes[i * 3 + 2].set_ylabel('PM10 [$\\mu g/m^3$]', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['pm1', 'pm2.5', 'pm10']\n",
    "\n",
    "val_test_res = pd.concat([\n",
    "    val_result, test_result]).reset_index(drop='index')\n",
    "\n",
    "for col in cols:\n",
    "    print(f'======== {col} prediction results ========')\n",
    "    total_r2 = calc_r2(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_r2 = calc_r2(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_r2 = calc_r2(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total R square: ', total_r2)\n",
    "    print('Train R square: ', train_r2)\n",
    "    print('Test R square: ', test_r2)\n",
    "    print()\n",
    "\n",
    "    total_nmse = calc_nmse(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_nmse = calc_nmse(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_nmse = calc_nmse(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total NMSE: ', total_nmse)\n",
    "    print('Train NMSE: ', train_nmse)\n",
    "    print('Test NMSE: ', test_nmse)\n",
    "    print()\n",
    "\n",
    "    total_fb = calc_fb(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_fb = calc_fb(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_fb = calc_fb(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total FB: ', total_fb)\n",
    "    print('Train FB: ', train_fb)\n",
    "    print('Test FB: ', test_fb)\n",
    "    print()\n",
    "\n",
    "    total_b = calc_b(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_b = calc_b(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_b = calc_b(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total B: ', total_b)\n",
    "    print('Train B: ', train_b)\n",
    "    print('Test B: ', test_b)\n",
    "    print()\n",
    "\n",
    "    total_corr = calc_corrcoef(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_corr = calc_corrcoef(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_corr = calc_corrcoef(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total Correlation Coeff: ', total_corr)\n",
    "    print('Train Correlation Coeff: ', train_corr)\n",
    "    print('Test Correlation Coeff: ', test_corr)\n",
    "    print()\n",
    "\n",
    "    pd.DataFrame({'Total': [total_r2, total_nmse, total_fb, total_b, total_corr],\n",
    "                  'Train': [train_r2, train_nmse, train_fb, train_b, train_corr],\n",
    "                  'Test': [test_r2, test_nmse, test_fb, test_b, test_corr]}).to_csv(\n",
    "        f'C:/Users/son/Desktop/lstm/lstm/training/result/result_{col}.csv', index=False, float_format='%.3f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1658475463206,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "POQTWHXwREC_",
    "outputId": "026cc530-e24c-4ff1-d6f5-9cdda2407084",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D, LSTM, BatchNormalization, LeakyReLU, TimeDistributed, GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input_tensor = Input(shape=(X_train.shape[1], X_train.shape[2]), name='input')\n",
    "\n",
    "    x = Conv1D(512, kernel_size=3, strides=1, padding='valid')(input_tensor)\n",
    "    x = GRU(units=256, activation='tanh', kernel_initializer='he_uniform', return_sequences=True)(input_tensor)\n",
    "    # x = GRU(units=192, activation='tanh', kernel_initializer='he_uniform', return_sequences=True)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation=LeakyReLU(alpha=0.05))(x)\n",
    "    x = Dropout(0.45)(x)\n",
    "    output = Dense(y.shape[2], 'relu', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output, name=f'lstm_v{hyper_params[\"version\"]}')\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hyper_params[\"lr\"]), loss=root_mean_squared_error,\n",
    "                  metrics=RootMeanSquaredError())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1658475540280,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "NSKgDI6WRL92",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"name\": \"PM2.5 Prediction test\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": 300,\n",
    "    \"version\": \"C1\",\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"offset\": OFFSET,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1658475541756,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "oFeUTUVZRXYz",
    "outputId": "74c8460f-a81b-4483-c21d-cb9d418cd5db",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "res_dir = f'training/v{hyper_params[\"version\"]}'\n",
    "\n",
    "if os.path.exists(res_dir):\n",
    "    shutil.rmtree(res_dir)\n",
    "\n",
    "os.makedirs(res_dir)\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=15, mode='min', verbose=1)\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=res_dir + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=1,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1658475546427,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "qUdrINM6Rb-O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D, LSTM, BatchNormalization, LeakyReLU, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input_tensor = Input(shape=(X_train.shape[1], X_train.shape[2]), name='input')\n",
    "\n",
    "    x = Conv1D(128, kernel_size=3, strides=1, padding='valid')(input_tensor)\n",
    "    x = LSTM(units=256, activation='tanh', kernel_initializer='he_uniform', return_sequences=True)(x)\n",
    "    x = LSTM(units=192, activation='tanh', kernel_initializer='he_uniform', return_sequences=True)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation=LeakyReLU(alpha=0.05))(x)\n",
    "    x = Dropout(0.45)(x)\n",
    "    output = Dense(y.shape[2], name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output, name=f'lstm_v{hyper_params[\"version\"]}')\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hyper_params[\"lr\"]), loss=root_mean_squared_error,\n",
    "                  metrics=RootMeanSquaredError())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dd in dfs:\n",
    "    x_ele, y_real = conv_to_dataset(\n",
    "        min_max_scale(\n",
    "            dd, [\n",
    "                'PM2.5_OUT',\n",
    "                'PM2.5_H_OUT',\n",
    "                'PM1_2.5_OUT',\n",
    "                'PM1_2.5_H_OUT',\n",
    "                'PM2.5_10_OUT',\n",
    "                'PM2.5_10_H_OUT',\n",
    "                'PERSON_NUMBER',\n",
    "            ], meta\n",
    "        ), FEATURE_LABEL, TARGET_LABEL, WINDOW_SIZE, OUTPUT_SIZE, OFFSET, verbose=False\n",
    "    )\n",
    "    y_hat = lstm.predict(x_ele, verbose=0)\n",
    "    _tmp_df = dd.iloc[WINDOW_SIZE + OFFSET + 1:].copy()\n",
    "    _tmp_df['PM1_PRED'] = y_hat[:, 0]\n",
    "    _tmp_df['PM2.5_PRED'] = y_hat[:, 1]\n",
    "    _tmp_df['PM10_PRED'] = y_hat[:, 2]\n",
    "    results.append(_tmp_df)\n",
    "\n",
    "res_df = pd.concat(results)\n",
    "ax = res_df[len(X_train):len(X_train) + len(X_val)].plot.scatter(x='PM2.5', y='PM2.5_PRED', c='y', figsize=(15, 15))\n",
    "res_df[len(X_train) + len(X_val):].plot.scatter(x='PM2.5', y='PM2.5_PRED', c='g', figsize=(15, 15), ax=ax)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "\n",
    "ax.plot(lims, lims, 'r-', linewidth=2, alpha=0.75, zorder=2)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1658475548803,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "yc4WXpaORdoa",
    "outputId": "4f8b6463-ea58-4743-f865-89fda239c5c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm = build_model()\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 752524,
     "status": "ok",
     "timestamp": 1658476305060,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "nOqRz47rRfBb",
    "outputId": "16493126-1e34-4494-b226-4e90b8c4fab6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "history = lstm.fit(x=X_train, y=y_train, batch_size=BATCH_SIZE, shuffle=False, epochs=hyper_params[\"epochs\"],\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   callbacks=[rlr_cb, ely_cb, mcp_cb])\n",
    "\n",
    "plt.figure(figsize=(28, 10))\n",
    "plt.plot(history.history['loss'], \"o--\", label='train')\n",
    "plt.plot(history.history['val_loss'], \"o--\", label='valid')\n",
    "plt.xlabel('Epochs', fontsize=15)\n",
    "plt.ylabel('Loss - RMSE', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "train_pred = lstm.predict(X_train)\n",
    "val_pred = lstm.predict(X_val)\n",
    "test_pred = lstm.predict(X_test)\n",
    "\n",
    "pred = np.concatenate((train_pred, val_pred, test_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kR3b5SoFVDRx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def calc_nmse(real, pred):\n",
    "    mse = np.sum((real - pred) ** 2)\n",
    "    size = len(real)\n",
    "    pred_sum = real.sum()\n",
    "    real_sum = pred.sum()\n",
    "    nmse = mse * size / (pred_sum * real_sum)\n",
    "    return nmse\n",
    "\n",
    "\n",
    "def calc_b(real, pred):\n",
    "    pred_mean = pred.mean()\n",
    "    real_mean = real.mean()\n",
    "    tmp_a = pred - pred_mean\n",
    "    tmp_b = real - real_mean\n",
    "    tmp_c = np.sum(np.square(real - real_mean))\n",
    "    return np.sum(tmp_a * tmp_b) / tmp_c\n",
    "\n",
    "def calc_fb(_real, _pred):\n",
    "    pred_mean = _pred.mean()\n",
    "    real_mean = _real.mean()\n",
    "    return 2 * (pred_mean - real_mean) / (pred_mean + real_mean)\n",
    "\n",
    "def calc_r2(real, pred):\n",
    "    return r2_score(real, pred)\n",
    "\n",
    "\n",
    "def calc_corrcoef(real, pred):\n",
    "    return np.corrcoef(real, pred)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1658476633640,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "_fjL7pQORl90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['pm1', 'pm2.5', 'pm10']\n",
    "\n",
    "val_test_res = pd.concat([\n",
    "    val_result, test_result]).reset_index(drop='index')\n",
    "\n",
    "for col in cols:\n",
    "    print(f'======== {col} prediction results ========')\n",
    "    total_r2 = calc_r2(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_r2 = calc_r2(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_r2 = calc_r2(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total R square: ', total_r2)\n",
    "    print('Train R square: ', train_r2)\n",
    "    print('Test R square: ', test_r2)\n",
    "    print()\n",
    "\n",
    "    total_nmse = calc_nmse(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_nmse = calc_nmse(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_nmse = calc_nmse(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total NMSE: ', total_nmse)\n",
    "    print('Train NMSE: ', train_nmse)\n",
    "    print('Test NMSE: ', test_nmse)\n",
    "    print()\n",
    "\n",
    "    total_fb = calc_fb(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_fb = calc_fb(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_fb = calc_fb(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total FB: ', total_fb)\n",
    "    print('Train FB: ', train_fb)\n",
    "    print('Test FB: ', test_fb)\n",
    "    print()\n",
    "\n",
    "    total_b = calc_b(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_b = calc_b(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_b = calc_b(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total B: ', total_b)\n",
    "    print('Train B: ', train_b)\n",
    "    print('Test B: ', test_b)\n",
    "    print()\n",
    "\n",
    "    total_corr = calc_corrcoef(total_result[col + ' real'].values, total_result[col + ' pred'].values)\n",
    "    train_corr = calc_corrcoef(train_result[col + ' real'].values, train_result[col + ' pred'].values)\n",
    "    test_corr = calc_corrcoef(val_test_res[col + ' real'].values, val_test_res[col + ' pred'].values)\n",
    "\n",
    "    print('Total Correlation Coeff: ', total_corr)\n",
    "    print('Train Correlation Coeff: ', train_corr)\n",
    "    print('Test Correlation Coeff: ', test_corr)\n",
    "    print()\n",
    "\n",
    "    # pd.DataFrame({'Total': [total_r2, total_nmse, total_fb, total_b, total_corr],\n",
    "    #               'Train': [train_r2, train_nmse, train_fb, train_b, train_corr],\n",
    "    #               'Test': [test_r2, test_nmse, test_fb, test_b, test_corr]}).to_csv(\n",
    "    #     f'/content/drive/MyDrive/result_{col}.csv', index=False, float_format='%.3f')\n",
    "\n",
    "    # calc_r2(total_result, train_result, val_result, test_result, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3336,
     "status": "ok",
     "timestamp": 1658476637528,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "pHLySHkUS3F1",
    "outputId": "ed6ab47d-e38d-4fa6-eebc-c9ec17315b3d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(lstm, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1658476637529,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "dW4YQt1mkUsc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm.save('C:/Users/son/Desktop/lstm/lstm/training/model_G2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658476638046,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "_0xbEDo4TUHr",
    "outputId": "296229ef-b881-4210-b43e-89ca85ad07c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm.save_weights('C:/Users/son/Desktop/lstm/lstm/training/model_G2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1658471441807,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "8zDq8XVsleJx",
    "outputId": "fc2d22e2-edab-4918-92d0-26bc7b88f598",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(lstm, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1658477079328,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "YX_zdAMTrHSp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm.save('/content/drive/MyDrive/saved_models/modelA-3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1658477086559,
     "user": {
      "displayName": "Jinseok Heo",
      "userId": "03306071473174633042"
     },
     "user_tz": -540
    },
    "id": "CiTrzKbHxddJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm.save_weights('/content/drive/MyDrive/saved_weights/modelA-3_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HzAGvdeEFVX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFTQOk2LKHi4jqeMOXuOqa",
   "collapsed_sections": [],
   "name": "Copy of pm25_predictor_1.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
