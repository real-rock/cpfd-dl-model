{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4caad7-85c2-4929-8357-9627e49fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../scripts/particles/')\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9af1dc5-b5e9-42fe-aea6-a4d07e747b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler as dh\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2243187d-51e5-4683-a71c-bde4f165bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "inputs = [\n",
    "    'PM1_2.5_OUT',\n",
    "    'PM1_2.5_H_OUT',\n",
    "    'PM2.5_OUT',\n",
    "    'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT',\n",
    "    'PM2.5_10_H_OUT',\n",
    "    'PERSON_NUMBER',\n",
    "    'AIR_PURIFIER',\n",
    "    'WINDOW',\n",
    "    'AIR_CONDITIONER',\n",
    "    'DOOR',\n",
    "    'WIND_DEG',\n",
    "    'HUMIDITY'\n",
    "]\n",
    "\n",
    "model_dir = '../../projects/particle/model'\n",
    "model_name = 'conv_20'\n",
    "model_path = model_dir + '/' + model_name\n",
    "\n",
    "config_path = model_path + \"/config.json\"\n",
    "f = open(config_path, \"r\")\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "in_time_step = config[\"model\"][\"window_size\"]\n",
    "out_time_step = 1\n",
    "offset = config[\"model\"][\"offset\"]\n",
    "\n",
    "del_mean = -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7c4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{model_path}/result/model/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69aecd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../../storage/particle/weather.csv', index_col='DATE',\n",
    "                         parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180)\n",
    "\n",
    "df_org = dh.load_data('../../storage/particle/data.csv')\n",
    "df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "excludes = ['PERSON_NUMBER', 'AIR_PURIFIER',\n",
    "            'AIR_CONDITIONER', 'WINDOW', 'DOOR']\n",
    "df = dh.apply_moving_average(pd.concat([df_org, weather_df], axis=1),\n",
    "                             window=config['data']['moving_average_window'],\n",
    "                             method=config['data']['moving_average_method'],\n",
    "                             excludes=excludes,\n",
    "                             min_periods=1)\n",
    "df = pd.concat([df, df_org[excludes]], axis=1)\n",
    "df[excludes] = df[excludes].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = dh.trim_df(df, config['data']['dates'])\n",
    "val_size = config['data']['validation']\n",
    "test_size = config['data']['test']\n",
    "\n",
    "train_dfs, val_dfs, test_dfs = dh.train_test_split_df(dfs, val_size, test_size)\n",
    "meta_df = pd.concat(train_dfs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164c3793-2a7b-43ff-bf76-ef2b378ab3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = config['model']['window_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d10cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(_dfs, in_time_step, delta_mean):\n",
    "    w = [0.71440267, 0.68195107, 0.6384208]\n",
    "    new_dfs = []\n",
    "    \n",
    "    for i, _df in enumerate(_dfs):\n",
    "        t_df = _df.copy()\n",
    "        delta = np.random.normal(loc=delta_mean, scale=2, size=len(_df))\n",
    "        t_df['PM1_OUT'] = np.maximum(t_df['PM1_OUT'] + delta, 0)\n",
    "        t_df['PM2.5_OUT'] = np.maximum(t_df['PM2.5_OUT'] + delta, 0)\n",
    "        t_df['PM10_OUT'] = np.maximum(t_df['PM10_OUT'] + delta, 0)\n",
    "        t_df['PM1_H_OUT'] = np.maximum(t_df['PM1_H_OUT'] + delta * w[0], 0)\n",
    "        t_df['PM2.5_H_OUT'] = np.maximum(t_df['PM2.5_H_OUT'] + delta * w[1], 0)\n",
    "        t_df['PM10_H_OUT'] = np.maximum(t_df['PM10_H_OUT'] + delta * w[2], 0)\n",
    "        new_dfs.append(t_df)\n",
    "    return dh.dfs_to_dataset(new_dfs, meta_df, inputs, outputs, in_time_step=in_time_step, out_time_step=out_time_step, offset=offset, excludes=outputs)\n",
    "\n",
    "X_test, y_test = to_dataset(test_dfs, win_size, del_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341bba93-1de4-4ea8-929c-accc09a83a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 2s 828us/step\n"
     ]
    }
   ],
   "source": [
    "NUM_ITER = 10000\n",
    "cis = [x for x in np.arange(0, 1 + 0.05, 0.05)]\n",
    "dropouts = [x for x in np.arange(0.2, 0.6 + 0.05, 0.05)]\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d739186-2be3-4b11-9f8f-f3c10380ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ac80bf-0433-4a03-a444-6fddc66e5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f412319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling1D,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling1D,\n",
    "    Attention,\n",
    "    Permute,\n",
    ")\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_tensor = Input(shape=(60, 13), name=\"input\")\n",
    "x = Conv1D(32, kernel_size=3, kernel_initializer='he_uniform', activation='relu', strides=1, padding='same')(input_tensor)\n",
    "x = MaxPooling1D(pool_size=5, strides=3)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, kernel_initializer='he_uniform', activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(y_test.shape[2], kernel_initializer='he_uniform', activation=\"relu\", name=\"output\")(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=input_tensor,\n",
    "    outputs=output,\n",
    "    name=f'{config[\"name\"].lower()}_v{config[\"version\"]}',\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=config[\"model\"][\"lr\"]),\n",
    "    loss=config[\"model\"][\"loss\"].lower(),\n",
    "    metrics=RootMeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70913db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60d8859-5e5c-4099-b70d-3f2f1171e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "def create_dropout_predict_function(_conf, _weights, _dropout):\n",
    "    conf = _conf\n",
    "    for layer in conf[\"layers\"]:\n",
    "        if layer[\"class_name\"] == \"Dropout\":\n",
    "            layer[\"config\"][\"rate\"] = _dropout\n",
    "        elif \"dropout\" in layer[\"config\"].keys():\n",
    "            layer[\"config\"][\"dropout\"] = _dropout\n",
    "\n",
    "    # if type(_model) == Sequential:\n",
    "    #     model_dropout = Sequential.from_config(conf)\n",
    "    # else:\n",
    "        # model_dropout = Model.from_config(conf)\n",
    "\n",
    "    model_dropout = Model.from_config(conf)\n",
    "    model_dropout.set_weights(_weights)\n",
    "\n",
    "    return model_dropout\n",
    "\n",
    "def predict_with_dropout(_conf, _weights, _X, _y, _dropout, num_iter):\n",
    "    num_samples = _X.shape[0]\n",
    "\n",
    "    dropout_prediction = create_dropout_predict_function(_conf, _weights, _dropout)\n",
    "    predictions = np.zeros((num_iter, _y.shape[0], _y.shape[1]))\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        for i in range(num_iter):\n",
    "            predictions[i] = dropout_prediction(tf.convert_to_tensor(_X), training=True)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "208ff293-5c06-4d57-9647-e602cad0a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def calc_ci(_X, _y, predictions, conf_int, num_iter):\n",
    "    ddof = num_iter - 1\n",
    "    num_samples = len(_y)\n",
    "    m = np.mean(predictions, axis=0)\n",
    "    ci = stats.t.interval(\n",
    "        conf_int, ddof, loc=m, scale=stats.sem(predictions, ddof=ddof, axis=0)\n",
    "    )\n",
    "\n",
    "    _res = np.zeros(3)\n",
    "    _dfs = []\n",
    "    for i in range(3):\n",
    "        _df = pd.DataFrame(\n",
    "            {\"real\": _y[:, i], \"lower\": ci[0][:, i], \"upper\": ci[1][:, i], \"pred\": pred[:, i]}\n",
    "        )\n",
    "        percentage = (\n",
    "            len(_df[(_df[\"real\"] <= _df[\"upper\"]) & (_df[\"real\"] >= _df[\"lower\"])])\n",
    "            / num_samples\n",
    "            * 100\n",
    "        )\n",
    "        _res[i] = percentage\n",
    "        _dfs.append(_df)\n",
    "    return _res, _dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b472e2-e2f9-4e95-8744-b0c8100cfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_folder(path):\n",
    "    if os.path.exists(path):\n",
    "        cmd = input(f'Folder name `{path}` already exsists. You mean overwrite?[Y/n]')\n",
    "        if cmd == 'Y' or cmd == 'y':\n",
    "            shutil.rmtree(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "proj_dir = f'../../projects/particle/ci_result/pm{del_mean:02d}'\n",
    "\n",
    "create_folder(proj_dir + \"/predict\")\n",
    "create_folder(proj_dir + \"/ci\")\n",
    "\n",
    "for dropout in dropouts:\n",
    "    X, y = to_dataset(test_dfs, win_size, del_mean)\n",
    "    predict = predict_with_dropout(conf, weights, X, y.reshape(-1, 3), dropout, NUM_ITER)\n",
    "    np.save(f\"{proj_dir}/predict/d_{dropout:.02f}.npy\", predict)\n",
    "    for ci in cis:\n",
    "        res, dfs = calc_ci(X_test, y_test.reshape(-1, 3), predict, ci, NUM_ITER)\n",
    "        for idx, df in enumerate(dfs):\n",
    "            df.to_csv(\n",
    "                f\"{proj_dir}/ci/d_{dropout:.02f}_ci_{ci:.02f}_{outputs[idx]}.csv\",\n",
    "                index=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('/home/jiheo/workspace/deep_learning/projects/particle/ci_result/2022-09-21_06:49/predict/d_0.25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_data[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eba58e-32f6-4f20-b00d-4e8eff7c69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dropout in dropouts:\n",
    "    predict = np.load(f'{proj_dir}/predict/d_{dropout:.02f}.npy')\n",
    "    for ci in cis:\n",
    "        res, dfs = calc_ci(X_test, y_test.reshape(-1, 3), predict, ci, NUM_ITER)\n",
    "        for idx, df in enumerate(dfs):\n",
    "            df.to_csv(\n",
    "                f\"{proj_dir}/ci/d_{dropout:.02f}_ci_{ci:.02f}_{outputs[idx]}.csv\",\n",
    "                index=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a315b6b-5344-41a1-9075-670c067b4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    res = np.zeros((len(dropouts) * len(cis), 3))\n",
    "    res_index = 0\n",
    "    for dropout in dropouts:\n",
    "        for ci in cis:\n",
    "            path = f\"{proj_dir}/ci/d_{dropout:.2f}_ci_{ci:.2f}_{outputs[idx]}.csv\"\n",
    "            df = pd.read_csv(path)\n",
    "            df = df[[\"real\", \"lower\", \"upper\", \"pred\"]]\n",
    "            score = (\n",
    "                len(df[(df[\"real\"] <= df[\"upper\"]) & (df[\"real\"] >= df[\"lower\"])])\n",
    "                / len(df)\n",
    "                * 100\n",
    "            )\n",
    "            res[res_index] = np.array([dropout, ci, score])\n",
    "            res_index += 1\n",
    "    pd.DataFrame(res, columns=[\"dropout\", \"ci\", \"score\"]).to_csv(\n",
    "        f\"{proj_dir}/ci_{outputs[idx]}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bc57d-fb8d-4ff5-bdb0-afb7b8a7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "pm1_ci = pd.read_csv(f'{proj_dir}/ci_pm1.csv')\n",
    "for dropout in dropouts:\n",
    "    if ax is None:\n",
    "        ax = pm1_ci[pm1_ci[\"dropout\"] == dropout].plot(\n",
    "            x=\"ci\", y=\"score\", figsize=(12, 10)\n",
    "        )\n",
    "    else:\n",
    "        ax = pm1_ci[pm1_ci[\"dropout\"] == dropout].plot(\n",
    "            x=\"ci\", y=\"score\", figsize=(12, 10), ax=ax\n",
    "        )\n",
    "\n",
    "legned_label = [f\"dropout={x:.2f}\" for x in dropouts]\n",
    "ax.legend(legned_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3eece1-e9ad-4205-b96e-4b464302a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_test_df = pd.read_csv(f\"{proj_dir}/ci/d_0.55_ci_0.95_pm1.csv\")\n",
    "ax = ci_test_df.plot(y=\"pred\", figsize=(30, 10), color=\"r\")\n",
    "ax = ci_test_df.plot(y=\"real\", figsize=(30, 10), color=\"b\", ax=ax)\n",
    "ax.fill_between(\n",
    "    ci_test_df.index,\n",
    "    ci_test_df[\"lower\"],\n",
    "    ci_test_df[\"upper\"],\n",
    "    facecolor=\"green\",\n",
    "    alpha=0.2,\n",
    "    interpolate=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c296132-e944-4194-8319-352d3f4cf70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4088fd0d3796640b1c65f1ddd822ba54c2009473962059d86be4eae2585c4d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
