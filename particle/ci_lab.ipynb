{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4caad7-85c2-4929-8357-9627e49fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af1dc5-b5e9-42fe-aea6-a4d07e747b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import particle_data\n",
    "from particle_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243187d-51e5-4683-a71c-bde4f165bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = [\"PM1\", \"PM2.5\", \"PM10\"]\n",
    "FEATURE_LABEL = [\n",
    "    \"PM1_2.5_OUT\",\n",
    "    \"PM1_2.5_H_OUT\",\n",
    "    \"PM2.5_OUT\",\n",
    "    \"PM2.5_H_OUT\",\n",
    "    \"PM2.5_10_OUT\",\n",
    "    \"PM2.5_10_H_OUT\",\n",
    "    \"PERSON_NUMBER\",\n",
    "    \"AIR_PURIFIER\",\n",
    "    \"WINDOW\",\n",
    "    \"AIR_CONDITIONER\",\n",
    "    \"DOOR\",\n",
    "]\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "OFFSET = 0\n",
    "OUTPUT_SIZE = 1\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff4184-b89b-4f4c-bf3b-679d8301e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dfs(_dfs, target_date):\n",
    "    _train_dfs = []\n",
    "    _test_dfs = []\n",
    "    for _d in _dfs:\n",
    "        if _d.index[0] < target_date and _d.index[-1] > target_date:\n",
    "            _train_dfs.append(_d.loc[:target_date])\n",
    "            _test_dfs.append(_d.loc[target_date:])\n",
    "        elif _d.index[0] >= target_date:\n",
    "            _test_dfs.append(_d)\n",
    "        else:\n",
    "            _train_dfs.append(_d)\n",
    "    return _train_dfs, _test_dfs\n",
    "\n",
    "def train_test_split_df(_dfs, val_size, test_size):\n",
    "    _tot_df = pd.concat(_dfs)\n",
    "    _tot_len = len(_tot_df)\n",
    "    _train_len = int((1 - val_size - test_size) * _tot_len)\n",
    "    _val_len = int(val_size * _tot_len)\n",
    "    _train_dfs, _test_dfs = split_dfs(_dfs, _tot_df.index[_train_len])\n",
    "    _val_dfs, _test_dfs = split_dfs(_test_dfs, _tot_df.index[_train_len + _val_len])\n",
    "    return _train_dfs, _val_dfs, _test_dfs\n",
    "\n",
    "def translate_to_dataset(_dfs, _meta=None):\n",
    "    _m = _meta\n",
    "    if _meta == None:\n",
    "        _m = get_meta(_dfs, [\n",
    "            \"PERSON_NUMBER\",\n",
    "            \"PM2.5_OUT\",\n",
    "            \"PM2.5_H_OUT\",\n",
    "            \"PM1_2.5_OUT\",\n",
    "            \"PM1_2.5_H_OUT\",\n",
    "            \"PM2.5_10_OUT\",\n",
    "            \"PM2.5_10_H_OUT\",\n",
    "            \"PM1_OUT\",\n",
    "            \"PM1_H_OUT\",\n",
    "            \"PM10_OUT\",\n",
    "            \"PM10_H_OUT\",\n",
    "            # \"HUMIDITY\",\n",
    "        ],)\n",
    "    _X, _y = gen_dataset(\n",
    "        _dfs,\n",
    "        _m,\n",
    "        features=FEATURE_LABEL,\n",
    "        targets=TARGET_LABEL,\n",
    "        window_size=WINDOW_SIZE,\n",
    "        output_size=OUTPUT_SIZE,\n",
    "        offset=OFFSET,\n",
    "        scale_cols=[\n",
    "                    'PM2.5_OUT',\n",
    "                    'PM2.5_H_OUT',\n",
    "                    'PM1_2.5_OUT',\n",
    "                    'PM1_2.5_H_OUT',\n",
    "                    'PM2.5_10_OUT',\n",
    "                    'PM2.5_10_H_OUT',\n",
    "                    'PERSON_NUMBER',\n",
    "                ],\n",
    "        scale=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return _X, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e240b-2fac-44ed-9821-fdf95436843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class ProjectHanlder:\n",
    "    def __init__(self, src):\n",
    "        config_path = src + \"/config.json\"\n",
    "        f = open(config_path, \"r\")\n",
    "        self.config_dict = json.load(f)\n",
    "        f.close()\n",
    "        self.model = None\n",
    "        self.root_dir = None\n",
    "\n",
    "    def load_model(self):\n",
    "        self.root_dir = (\n",
    "            self.config_dict[\"root_dir\"]\n",
    "            + \"/\"\n",
    "            + self.config_dict[\"name\"]\n",
    "            + self.config_dict[\"version\"]\n",
    "        )\n",
    "        model_path = (\n",
    "            self.root_dir\n",
    "            + \"/\"\n",
    "            + self.config_dict[\"dirs\"][\"model\"]\n",
    "            + \"/\"\n",
    "            + self.config_dict[\"name\"].lower()\n",
    "            + \"_\"\n",
    "            + self.config_dict[\"version\"]\n",
    "            + \".h5\"\n",
    "        )\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        return self.model\n",
    "    \n",
    "    def load_prediction(self):\n",
    "        self.root_dir = (\n",
    "            self.config_dict[\"root_dir\"]\n",
    "            + \"/\"\n",
    "            + self.config_dict[\"name\"]\n",
    "            + self.config_dict[\"version\"]\n",
    "        )\n",
    "        pred_path = (\n",
    "            self.root_dir\n",
    "            + \"/\"\n",
    "            + self.config_dict[\"dirs\"][\"predict\"]\n",
    "            + \"/\"\n",
    "            + \"predict.csv\"\n",
    "        )\n",
    "        res_df = pd.read_csv(pred_path)\n",
    "        res_df.index = res_df.pop('DATE').apply(pd.to_datetime)\n",
    "        return res_df\n",
    "    \n",
    "    def clear_session(self):\n",
    "        del self.model\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1d095-c74e-49f0-8d88-7db78aa3be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    ph = ProjectHanlder(\"project/GRU/GRUkt01\")\n",
    "    model = ph.load_model()\n",
    "    prediction = ph.load_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76964731-fdaf-4818-aa6a-ffae29f3eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = load_pm(\"../data/data.csv\")\n",
    "add_diff(df_org)\n",
    "df = apply_moving_average(\n",
    "    df_org, 'median', ph.config_dict[\"model\"][\"data\"][\"moving_average_window\"], True, 3\n",
    ")\n",
    "\n",
    "dfs = trim_df(df, ph.config_dict[\"model\"][\"data\"][\"used_data\"])\n",
    "meta = ph.config_dict['model']['data']['meta']\n",
    "\n",
    "train_dfs, val_dfs, test_dfs = train_test_split_df(dfs, ph.config_dict[\"model\"][\"data\"][\"validation\"], ph.config_dict[\"model\"][\"data\"][\"test\"])\n",
    "\n",
    "X_train, y_train = translate_to_dataset(train_dfs)\n",
    "X_val, y_val = translate_to_dataset(val_dfs, meta)\n",
    "X_test, y_test = translate_to_dataset(test_dfs, meta)\n",
    "\n",
    "print(\"X_train, y_train shape: \", X_train.shape, y_train.shape)\n",
    "print(\"X_val, y_val shape: \", X_val.shape, y_val.shape)\n",
    "print(\"X_test, y_test shape: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bba93-1de4-4ea8-929c-accc09a83a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 10000\n",
    "cis = [x for x in np.arange(0, 1 + 0.05, 0.05)]\n",
    "dropouts = [x for x in np.arange(0.2, 0.6 + 0.05, 0.05)]\n",
    "targets = [\"pm1\", \"pm2.5\", \"pm10\"]\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d739186-2be3-4b11-9f8f-f3c10380ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "ph.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac80bf-0433-4a03-a444-6fddc66e5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d8859-5e5c-4099-b70d-3f2f1171e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "def create_dropout_predict_function(_conf, _weights, _dropout):\n",
    "    conf = _conf\n",
    "    for layer in conf[\"layers\"]:\n",
    "        if layer[\"class_name\"] == \"Dropout\":\n",
    "            layer[\"config\"][\"rate\"] = _dropout\n",
    "        elif \"dropout\" in layer[\"config\"].keys():\n",
    "            layer[\"config\"][\"dropout\"] = _dropout\n",
    "\n",
    "    # if type(_model) == Sequential:\n",
    "    #     model_dropout = Sequential.from_config(conf)\n",
    "    # else:\n",
    "        # model_dropout = Model.from_config(conf)\n",
    "        \n",
    "    model_dropout = Model.from_config(conf)\n",
    "    model_dropout.set_weights(_weights)\n",
    "\n",
    "    return model_dropout\n",
    "\n",
    "def predict_with_dropout(_conf, _weights, _X, _y, _dropout, num_iter):\n",
    "    num_samples = _X.shape[0]\n",
    "\n",
    "    dropout_prediction = create_dropout_predict_function(_conf, _weights, _dropout)\n",
    "    predictions = np.zeros((num_iter, _y.shape[0], _y.shape[1]))\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        for i in range(num_iter):\n",
    "            predictions[i] = dropout_prediction(tf.convert_to_tensor(_X), training=True)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ff293-5c06-4d57-9647-e602cad0a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def calc_ci(_X, _y, predictions, conf_int, num_iter):\n",
    "    ddof = num_iter - 1\n",
    "    num_samples = len(_y)\n",
    "    m = np.mean(predictions, axis=0)\n",
    "    ci = stats.t.interval(\n",
    "        conf_int, ddof, loc=m, scale=stats.sem(predictions, ddof=ddof, axis=0)\n",
    "    )\n",
    "\n",
    "    _res = np.zeros(3)\n",
    "    _dfs = []\n",
    "    for i in range(3):\n",
    "        _df = pd.DataFrame(\n",
    "            {\"real\": _y[:, i], \"lower\": ci[0][:, i], \"upper\": ci[1][:, i], \"pred\": pred[:, i]}\n",
    "        )\n",
    "        percentage = (\n",
    "            len(_df[(_df[\"real\"] <= _df[\"upper\"]) & (_df[\"real\"] >= _df[\"lower\"])])\n",
    "            / num_samples\n",
    "            * 100\n",
    "        )\n",
    "        _res[i] = percentage\n",
    "        _dfs.append(_df)\n",
    "    return _res, _dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db5666-7c2c-4491-8e28-1756ee722ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:, 1]\n",
    "resd = np.zeros(len(np_pred))\n",
    "resdpred[0, 1] - resd[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e1a50-a053-4587-aa0c-0cf41374ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 17000\n",
    "\n",
    "data = np_pred[:, time, 1] - pred[time, 1]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.mean()[0], df.std()[0])\n",
    "df.plot(kind='hist', bins=100, figsize=(22, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b472e2-e2f9-4e95-8744-b0c8100cfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "proj_dir = f'ci_result/{dt.datetime.now().strftime(\"%Y-%m-%d_%H:%M\")}'\n",
    "\n",
    "create_folder(proj_dir + \"/predict\")\n",
    "create_folder(proj_dir + \"/ci\")\n",
    "\n",
    "for dropout in dropouts:\n",
    "    predict = predict_with_dropout(conf, weights, X_test, y_test.reshape(-1, 3), dropout, NUM_ITER)\n",
    "    np.save(f\"{proj_dir}/predict/d_{dropout:.02f}.npy\", predict)\n",
    "    for ci in cis:\n",
    "        res, dfs = calc_ci(X_test, y_test.reshape(-1, 3), predict, ci, NUM_ITER)\n",
    "        for idx, df in enumerate(dfs):\n",
    "            df.to_csv(\n",
    "                f\"{proj_dir}/ci/d_{dropout:.02f}_ci_{ci:.02f}_{targets[idx]}.csv\",\n",
    "                index=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85797d5a-a4ca-4da5-98c5-2ed1293e1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = 'ci_result/2022-08-19_20:38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eba58e-32f6-4f20-b00d-4e8eff7c69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dropout in dropouts:\n",
    "    predict = np.load(f'{proj_dir}/predict/d_{dropout:.02f}.npy')\n",
    "    for ci in cis:\n",
    "        res, dfs = calc_ci(X_test, y_test.reshape(-1, 3), predict, ci, NUM_ITER)\n",
    "        for idx, df in enumerate(dfs):\n",
    "            df.to_csv(\n",
    "                f\"{proj_dir}/ci/d_{dropout:.02f}_ci_{ci:.02f}_{targets[idx]}.csv\",\n",
    "                index=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a315b6b-5344-41a1-9075-670c067b4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    res = np.zeros((len(dropouts) * len(cis), 3))\n",
    "    res_index = 0\n",
    "    for dropout in dropouts:\n",
    "        for ci in cis:\n",
    "            path = f\"{proj_dir}/ci/d_{dropout:.2f}_ci_{ci:.2f}_{targets[idx]}.csv\"\n",
    "            df = pd.read_csv(path)\n",
    "            df = df[[\"real\", \"lower\", \"upper\", \"pred\"]]\n",
    "            score = (\n",
    "                len(df[(df[\"real\"] <= df[\"upper\"]) & (df[\"real\"] >= df[\"lower\"])])\n",
    "                / len(df)\n",
    "                * 100\n",
    "            )\n",
    "            res[res_index] = np.array([dropout, ci, score])\n",
    "            res_index += 1\n",
    "    pd.DataFrame(res, columns=[\"dropout\", \"ci\", \"score\"]).to_csv(\n",
    "        f\"{proj_dir}/ci_{targets[idx]}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bc57d-fb8d-4ff5-bdb0-afb7b8a7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "pm1_ci = pd.read_csv(f'{proj_dir}/ci_pm1.csv')\n",
    "for dropout in dropouts:\n",
    "    if ax is None:\n",
    "        ax = pm1_ci[pm1_ci[\"dropout\"] == dropout].plot(\n",
    "            x=\"ci\", y=\"score\", figsize=(12, 10)\n",
    "        )\n",
    "    else:\n",
    "        ax = pm1_ci[pm1_ci[\"dropout\"] == dropout].plot(\n",
    "            x=\"ci\", y=\"score\", figsize=(12, 10), ax=ax\n",
    "        )\n",
    "\n",
    "legned_label = [f\"dropout={x:.2f}\" for x in dropouts]\n",
    "ax.legend(legned_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3eece1-e9ad-4205-b96e-4b464302a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_test_df = pd.read_csv(f\"{proj_dir}/ci/d_0.55_ci_0.95_pm1.csv\")\n",
    "ax = ci_test_df.plot(y=\"pred\", figsize=(30, 10), color=\"r\")\n",
    "ax = ci_test_df.plot(y=\"real\", figsize=(30, 10), color=\"b\", ax=ax)\n",
    "ax.fill_between(\n",
    "    ci_test_df.index,\n",
    "    ci_test_df[\"lower\"],\n",
    "    ci_test_df[\"upper\"],\n",
    "    facecolor=\"green\",\n",
    "    alpha=0.2,\n",
    "    interpolate=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c296132-e944-4194-8319-352d3f4cf70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
