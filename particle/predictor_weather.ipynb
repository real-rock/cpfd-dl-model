{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0f37c-81af-4b3f-9b4b-5ab45fc071e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../scripts/particles/\")\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775d93e-6262-4742-9cc4-dfd234b0670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler as dh\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89c1c6-7349-4c85-892a-cd22bc346f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['PM1', 'PM2.5', 'PM10']\n",
    "inputs = [\n",
    "    'PM1_2.5_OUT',\n",
    "    'PM1_2.5_H_OUT',\n",
    "    'PM2.5_OUT',\n",
    "    'PM2.5_H_OUT',\n",
    "    'PM2.5_10_OUT',\n",
    "    'PM2.5_10_H_OUT',\n",
    "    'PERSON_NUMBER',\n",
    "    'AIR_PURIFIER',\n",
    "    'WINDOW',\n",
    "    'AIR_CONDITIONER',\n",
    "    'DOOR',\n",
    "    # 'TEMPERATURE',\n",
    "    #'WIND_SPEED',\n",
    "    'WIND_DEG',\n",
    "    'HUMIDITY'\n",
    "]\n",
    "\n",
    "in_time_step = 60\n",
    "offset = 1\n",
    "out_time_step = 1\n",
    "batch_size = 32\n",
    "\n",
    "config = {\n",
    "    \"name\": \"conv\",\n",
    "    \"description\": \"conv1D\",\n",
    "    \"version\": \"25\",\n",
    "    \"root_dir\": \"projects/particle/model\",\n",
    "    \"dirs\": {\n",
    "        \"weights\": \"training/weights\",\n",
    "        \"history\": \"training/history\",\n",
    "        \"metric\": \"result/metric\",\n",
    "        \"model\": \"result/model\",\n",
    "        \"predict\": \"result/predict\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"lr\": 0.0001,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": 300,\n",
    "        \"window_size\": in_time_step,\n",
    "        \"offset\": offset,\n",
    "        \"loss\": \"MSE\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"moving_average_window\": 20,\n",
    "        \"moving_average_method\": 'mean',\n",
    "        \"train\": 0.60,\n",
    "        \"validation\": 0.15,\n",
    "        \"test\": 0.25,\n",
    "        \"dates\": [\n",
    "            {\"start\": \"2022-05-07 09:40\", \"end\": \"2022-05-17 08:38\"},\n",
    "            {\"start\": \"2022-05-17 11:25\", \"end\": \"2022-05-30 23:26\"},\n",
    "            {\"start\": \"2022-06-01 22:40\", \"end\": \"2022-07-02 07:00\"},\n",
    "            {\"start\": \"2022-07-02 16:40\", \"end\": \"2022-07-09 07:13\"},\n",
    "            {\"start\": \"2022-07-09 14:30\", \"end\": \"2022-07-12 10:00\"},\n",
    "            {\"start\": \"2022-07-25 12:00\", \"end\": \"2022-08-01 10:00\"},\n",
    "            {\"start\": \"2022-08-03 09:00\", \"end\": \"2022-08-11 22:18\"},\n",
    "            {\"start\": \"2022-08-12 12:14\", \"end\": \"2022-08-20 00:00\"},\n",
    "            {\"start\": \"2022-08-20 09:38\", \"end\": \"2022-09-01 00:00\"},\n",
    "        ],\n",
    "        \"meta\": None\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6883f-cd2b-43cb-9f2d-5638585bfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = (\n",
    "    config[\"root_dir\"] + \"/\" + config[\"name\"] + \"_\" + config[\"version\"]\n",
    ")\n",
    "\n",
    "weights_dir = config[\"dirs\"][\"weights\"]\n",
    "history_dir = config[\"dirs\"][\"history\"]\n",
    "predict_dir = config[\"dirs\"][\"predict\"]\n",
    "model_dir = config[\"dirs\"][\"model\"]\n",
    "metric_dir = config[\"dirs\"][\"metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21477b-f15a-4125-a74f-ed4e9100213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def create_folder(path):\n",
    "    if os.path.exists(path):\n",
    "        cmd = input(f'Folder name `{path}` already exsists. You mean overwrite?[Y/n]')\n",
    "        if cmd == 'Y' or cmd == 'y':\n",
    "            shutil.rmtree(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "create_folder(root_dir + \"/\" + weights_dir)\n",
    "create_folder(root_dir + \"/\" + history_dir)\n",
    "create_folder(root_dir + \"/\" + predict_dir)\n",
    "create_folder(root_dir + \"/\" + model_dir)\n",
    "create_folder(root_dir + \"/\" + metric_dir)\n",
    "\n",
    "with open(f\"{root_dir}/config.json\", \"w\") as outfile:\n",
    "    json.dump(config, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(usable_dates, val_size, test_size, **kwargs):\n",
    "    weather_df = pd.read_csv(\n",
    "        \"../../storage/particle/weather.csv\", index_col=\"DATE\", parse_dates=True\n",
    "    )[[\"TEMPERATURE\", \"WIND_DEG\", \"WIND_SPEED\", \"HUMIDITY\"]]\n",
    "    weather_df[\"WIND_DEG\"] = np.sin(weather_df[\"WIND_DEG\"].values * np.pi / 180 / 4)\n",
    "\n",
    "    df_org = dh.load_data()\n",
    "    df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "    excludes = [\"PERSON_NUMBER\", \"AIR_PURIFIER\", \"AIR_CONDITIONER\", \"WINDOW\", \"DOOR\", \"WIND_DEG\"]\n",
    "    df_org = pd.concat([df_org, weather_df], axis=1)\n",
    "    df = dh.apply_moving_average(\n",
    "        df_org, min_periods=1, excludes=excludes, **kwargs\n",
    "    )\n",
    "    df = pd.concat([df, df_org[excludes]], axis=1)[inputs + outputs]\n",
    "\n",
    "    dfs = dh.trim_df(df, usable_dates)\n",
    "\n",
    "    return dh.train_test_split_df(dfs, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = get_datasets(\n",
    "    config[\"data\"][\"dates\"],\n",
    "    config[\"data\"][\"validation\"],\n",
    "    config[\"data\"][\"test\"],\n",
    "    window=config[\"data\"][\"moving_average_window\"],\n",
    "    method=config[\"data\"][\"moving_average_method\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f78e8d-a148-4450-8dcd-1de9cf1a2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('storage/particle/weather.csv', index_col='DATE',\n",
    "                         parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180 / 4)\n",
    "\n",
    "df_org = dh.load_data(\"storage/particle/data.csv\")\n",
    "df_org = dh.add_pm_diff(df_org)\n",
    "\n",
    "excludes = ['PERSON_NUMBER', 'AIR_PURIFIER',\n",
    "            'AIR_CONDITIONER', 'WINDOW', 'DOOR']\n",
    "df = dh.apply_moving_average(pd.concat([df_org, weather_df], axis=1),\n",
    "                             window=config['data']['moving_average_window'],\n",
    "                             method=config['data']['moving_average_method'],\n",
    "                             excludes=excludes,\n",
    "                             min_periods=1)\n",
    "df = pd.concat([df, df_org[excludes]], axis=1)\n",
    "df[excludes] = df[excludes].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = dh.trim_df(df, config['data']['dates'])\n",
    "val_size = config['data']['validation']\n",
    "test_size = config['data']['test']\n",
    "\n",
    "train_dfs, val_dfs, test_dfs = dh.train_test_split_df(dfs, val_size, test_size)\n",
    "meta_df = pd.concat(train_dfs).describe()\n",
    "meta_df.to_csv(f'{root_dir}/meta.csv', index_label='component')\n",
    "config['data']['meta'] = f'{root_dir}/meta.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d4430-0e2e-4ece-a7c4-dab54e9d2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(_dfs, in_time_step):\n",
    "    return dh.dfs_to_dataset(_dfs, meta_df, inputs, outputs, in_time_step=in_time_step, out_time_step=out_time_step, offset=offset, excludes=outputs)\n",
    "\n",
    "win_size = config['model']['window_size']\n",
    "X_train, y_train = to_dataset(train_dfs, win_size)\n",
    "X_val, y_val = to_dataset(val_dfs, win_size)\n",
    "X_test, y_test = to_dataset(test_dfs, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba958c-bb6a-44ca-9092-cdb23eec8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=10, mode=\"min\", verbose=1, min_lr=1e-6\n",
    ")\n",
    "ely_cb = EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\", verbose=1)\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=root_dir\n",
    "    + \"/\"\n",
    "    + config[\"dirs\"][\"weights\"]\n",
    "    + \"/e{epoch:02d}-v{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    period=1,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9c2f5-a0d9-4428-81b3-0c67a27470ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling1D,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling1D,\n",
    "    Attention,\n",
    "    Permute,\n",
    ")\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    \n",
    "    a = Permute((2, 1))(inputs) # same transpose\n",
    "    a = Dense(inputs.shape[1], activation='softmax')(a)\n",
    "    \n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    output_attention_mul  = tf.keras.layers.multiply([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input_tensor = Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, kernel_initializer='he_uniform', activation='relu', strides=1, padding='same')(input_tensor)\n",
    "    # x = Conv1D(128, kernel_size=3, activation='relu', strides=1, padding=\"valid\")(x)\n",
    "    # x = GRU(\n",
    "    #     units=32,\n",
    "    #     activation=\"tanh\",\n",
    "    #     kernel_initializer=\"glorot_uniform\",\n",
    "    #     return_sequences=True,\n",
    "    # )(input_tensor)\n",
    "    # x = GRU(\n",
    "    #     units=160,\n",
    "    #     activation=\"tanh\",\n",
    "    #     kernel_initializer=\"he_uniform\",\n",
    "    #     return_sequences=True,\n",
    "    # )(x)\n",
    "    # x = attention_3d_block(x)\n",
    "    x = MaxPooling1D(pool_size=5, strides=3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, kernel_initializer='he_uniform', activation='relu')(x)\n",
    "    # x = Dropout(0.5)(x)\n",
    "    output = Dense(y_train.shape[2], kernel_initializer='he_uniform', activation=\"relu\", name=\"output\")(x)\n",
    "\n",
    "    _model = Model(\n",
    "        inputs=input_tensor,\n",
    "        outputs=output,\n",
    "        name=f'{config[\"name\"].lower()}_v{config[\"version\"]}',\n",
    "    )\n",
    "\n",
    "    _model.compile(\n",
    "        optimizer=Adam(learning_rate=config[\"model\"][\"lr\"]),\n",
    "        loss=config[\"model\"][\"loss\"].lower(),\n",
    "        metrics=RootMeanSquaredError(),\n",
    "    )\n",
    "\n",
    "    return _model\n",
    "\n",
    "\n",
    "model = build_model((X_train.shape[1], X_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b2afe-1abb-47dc-898e-dcbc23d2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    training_res = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        epochs=config[\"model\"][\"epochs\"],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[rlr_cb, ely_cb, mcp_cb],\n",
    "    )\n",
    "    pd.DataFrame(training_res.history).to_csv(\n",
    "        root_dir + \"/\" + config[\"dirs\"][\"history\"] + \"/history.csv\", index=False\n",
    "    )\n",
    "    plt.figure(figsize=(28, 10))\n",
    "    plt.plot(training_res.history[\"loss\"], \"o--\", label=\"train\")\n",
    "    plt.plot(training_res.history[\"val_loss\"], \"o--\", label=\"valid\")\n",
    "    plt.xlabel(\"Epochs\", fontsize=15)\n",
    "    plt.ylabel(\"Loss - RMSE\", fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a8b68-d311-4941-a185-52b040ff8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(_dfs, output_scaled=False):\n",
    "    res_dfs = []\n",
    "    for _df in _dfs:\n",
    "        df_cp = _df.copy()\n",
    "        _X, _y = dh.dfs_to_dataset([df_cp], meta_df, inputs, outputs, in_time_step=in_time_step)\n",
    "        y_hat = model.predict(_X, verbose=False)\n",
    "        df_cp = df_cp.iloc[in_time_step + out_time_step + offset - 1:]\n",
    "        for idx, output in enumerate(outputs):\n",
    "            if output_scaled:\n",
    "                min_val = meta_df[output]['min']\n",
    "                max_val = meta_df[output]['max']\n",
    "                df_cp[output + '_PRED'] = y_hat[:, idx] * (max_val - min_val) + min_val\n",
    "            else:\n",
    "                df_cp[output + '_PRED'] = y_hat[:, idx]\n",
    "        res_dfs.append(df_cp)\n",
    "    return pd.concat(res_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674e370-5426-4ce4-bbcd-1388fa112df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(f\"{root_dir}/{weights_dir}/e27-v8.17.h5\")\n",
    "# train_res = get_result(train_dfs)\n",
    "# train_res['TYPE'] = 'train'\n",
    "# val_res = get_result(val_dfs)\n",
    "# val_res['TYPE'] = 'val'\n",
    "# test_res = get_result(test_dfs)\n",
    "# test_res['TYPE'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c4dc-b7ea-485a-8aaf-3eccef3dcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.load_weights('project/GRU/GRU09/training/weights/e23-v17.85.h5')\n",
    "#model = tf.keras.models.load_model(\"../projects/particle/model/conv_17/result/model/conv_17.h5\")\n",
    "train_res = get_result(train_dfs)\n",
    "train_res['TYPE'] = 'train'\n",
    "val_res = get_result(val_dfs)\n",
    "val_res['TYPE'] = 'val'\n",
    "test_res = get_result(test_dfs)\n",
    "test_res['TYPE'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fbb44-34ea-43e0-bf0d-04b82e7cf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_res = pd.read_csv('../projects/particle/model/conv_09/result/predict/predict.csv', index_col='DATE', parse_dates=True)\n",
    "#train_res = total_res[total_res['TYPE'] == 'train']\n",
    "#val_res = total_res[total_res['TYPE'] == 'val']\n",
    "#test_res = total_res[total_res['TYPE'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfb840-4cb0-40d6-8932-1b5471128677",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(train_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e556433-8039-4949-85df-952c05785eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(val_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415855fa-4aa7-453a-89ca-a5cb3d3a0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.plot(test_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708177bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_res['PM2.5'] - test_res['PM2.5_PRED']).hist(bins=100, figsize=(22, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa474190",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_res['PM1'] - test_res['PM1_PRED']).hist(bins=100, figsize=(22, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bc8bd-1ec6-4a52-923d-39745b8265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "val_res.plot.scatter(x=\"PM2.5\", y=\"PM2.5_PRED\", c=\"y\", ax=ax)\n",
    "test_res.plot.scatter(x=\"PM2.5\", y=\"PM2.5_PRED\", c=\"g\", ax=ax)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "\n",
    "ax.plot(lims, lims, \"r-\", linewidth=2, alpha=0.75, zorder=2)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68b24f-dcc0-4760-bbfb-5f6b56d05284",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "cols = [\"pm1\", \"pm2.5\", \"pm10\"]\n",
    "total_res = pd.concat([train_res, val_res, test_res])\n",
    "res_dfs = [total_res, train_res, val_res, test_res]\n",
    "res_indices = [\"Total\", \"Train\", \"Validation\", \"Test\"]\n",
    "metric_funcs = [metrics.calc_r2, metrics.calc_corrcoef, metrics.calc_nmse, metrics.calc_fb, metrics.calc_b, metrics.calc_a_co]\n",
    "metrics_indices = [\"R Square\", \"Corr\", \"NMSE\", \"FB\", \"B\", \"a/C\"]\n",
    "\n",
    "\n",
    "def calc_metric(_f, _df, _col):\n",
    "    return _f(_df[_col].values, _df[_col + \"_PRED\"].values)\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"======== {col} prediction results ========\")\n",
    "    res_dict = {\n",
    "        \"Metric\": metrics_indices,\n",
    "        \"Total\": [],\n",
    "        \"Train\": [],\n",
    "        \"Validation\": [],\n",
    "        \"Test\": [],\n",
    "    }\n",
    "\n",
    "    for j, m in enumerate(metric_funcs):\n",
    "        for i, rd in enumerate(res_dfs):\n",
    "            s = calc_metric(m, rd, col.upper())\n",
    "            res_dict[res_indices[i]].append(s)\n",
    "\n",
    "    r_df = pd.DataFrame(res_dict)\n",
    "    print(r_df)\n",
    "    print()\n",
    "    if save:\n",
    "        r_df.to_csv(\n",
    "            f'{root_dir}/{config[\"dirs\"][\"metric\"]}/result_{col}.csv',\n",
    "            index=False,\n",
    "            float_format=\"%.3f\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe65902-ca3d-457f-ae34-1f419fca475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    total_res.to_csv(\n",
    "        root_dir + \"/\" + config[\"dirs\"][\"predict\"] + \"/predict.csv\",\n",
    "        index_label=\"DATE\",\n",
    "    )\n",
    "\n",
    "    model.save(\n",
    "        root_dir\n",
    "        + \"/\"\n",
    "        + config[\"dirs\"][\"model\"]\n",
    "        + f'/{config[\"name\"].lower()}_{config[\"version\"]}.h5'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecdf04-9339-443c-8167-42006999e263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4088fd0d3796640b1c65f1ddd822ba54c2009473962059d86be4eae2585c4d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
