{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0f37c-81af-4b3f-9b4b-5ab45fc071e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c605b-d12b-49c2-8453-c44b7e916036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import particle_data\n",
    "from particle_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89c1c6-7349-4c85-892a-cd22bc346f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = [\"PM1\", \"PM2.5\", \"PM10\"]\n",
    "FEATURE_LABEL = [\n",
    "    \"PM1_2.5_OUT\",\n",
    "    \"PM1_2.5_H_OUT\",\n",
    "    \"PM2.5_OUT\",\n",
    "    \"PM2.5_H_OUT\",\n",
    "    \"PM2.5_10_OUT\",\n",
    "    \"PM2.5_10_H_OUT\",\n",
    "    \"PERSON_NUMBER\",\n",
    "    \"AIR_PURIFIER\",\n",
    "    \"WINDOW\",\n",
    "    \"AIR_CONDITIONER\",\n",
    "    \"DOOR\",\n",
    "    \"TEMPERATURE\",\n",
    "    \"WIND_SPEED\",\n",
    "    \"WIND_DEG\",\n",
    "    \"HUMIDITY\",\n",
    "]\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "OFFSET = 0\n",
    "OUTPUT_SIZE = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "hyper_params = {\n",
    "    \"name\": \"Conv_Weather\",\n",
    "    \"description\": \"CONV WITH WEATHER\",\n",
    "    \"version\": \"06\",\n",
    "    \"root_dir\": \"project/Conv\",\n",
    "    \"dirs\": {\n",
    "        \"weights\": \"training/weights\",\n",
    "        \"history\": \"training/history\",\n",
    "        \"metric\": \"result/metric\",\n",
    "        \"model\": \"result/model\",\n",
    "        \"predict\": \"result/predict\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"lr\": 1e-05,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": 300,\n",
    "        \"window_size\": WINDOW_SIZE,\n",
    "        \"offset\": OFFSET,\n",
    "        \"loss\": \"MSE\",\n",
    "        \"data\": {\n",
    "            \"moving_average_window\": 15,\n",
    "            \"moving_average_method\": 'median',\n",
    "            \"train\": 0.60,\n",
    "            \"validation\": 0.15,\n",
    "            \"test\": 0.25,\n",
    "            \"used_data\": [\n",
    "                {\"start\": \"2022-05-07 09:40\", \"end\": \"2022-05-17 08:38\"},\n",
    "                {\"start\": \"2022-05-17 11:25\", \"end\": \"2022-05-30 23:26\"},\n",
    "                {\"start\": \"2022-06-01 22:40\", \"end\": \"2022-07-02 07:00\"},\n",
    "                {\"start\": \"2022-07-02 16:40\", \"end\": \"2022-07-09 07:13\"},\n",
    "                {\"start\": \"2022-07-09 14:30\", \"end\": \"2022-07-12 10:00\"},\n",
    "                {\"start\": \"2022-07-25 12:00\", \"end\": \"2022-08-01 10:00\"},\n",
    "                {\"start\": \"2022-08-03 09:00\", \"end\": \"2022-08-11 22:18\"},\n",
    "                {\"start\": \"2022-08-12 12:14\", \"end\": \"2022-08-20 00:00\"},\n",
    "            ],\n",
    "            \"meta\": None\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9abbf-2a8f-4a65-a618-653c4397754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../data/weather.csv', index_col='DATE', parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = weather_df['WIND_DEG'].values * np.pi / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba20bbb-31f9-4117-b812-baae1ade461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = load_pm(\"../data/data.csv\")\n",
    "add_diff(df_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f78e8d-a148-4450-8dcd-1de9cf1a2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_moving_average(\n",
    "    pd.concat([df_org, weather_df], axis=1), hyper_params[\"model\"][\"data\"][\"moving_average_method\"], hyper_params[\"model\"][\"data\"][\"moving_average_window\"], True\n",
    ")\n",
    "df[['PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR']].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = trim_df(df, hyper_params[\"model\"][\"data\"][\"used_data\"])\n",
    "train_dfs, val_dfs, test_dfs = train_test_split_df(dfs, hyper_params[\"model\"][\"data\"][\"validation\"], hyper_params[\"model\"][\"data\"][\"test\"])\n",
    "meta = get_meta(train_dfs, [\n",
    "            \"PERSON_NUMBER\",\n",
    "            \"PM2.5_OUT\",\n",
    "            \"PM2.5_H_OUT\",\n",
    "            \"PM1_2.5_OUT\",\n",
    "            \"PM1_2.5_H_OUT\",\n",
    "            \"PM2.5_10_OUT\",\n",
    "            \"PM2.5_10_H_OUT\",\n",
    "            \"PM1_OUT\",\n",
    "            \"PM1_H_OUT\",\n",
    "            \"PM10_OUT\",\n",
    "            \"PM10_H_OUT\",\n",
    "            \"TEMPERATURE\",\n",
    "            \"WIND_SPEED\",\n",
    "            \"WIND_DEG\",\n",
    "            \"HUMIDITY\",\n",
    "        ],)\n",
    "hyper_params['model']['data']['meta'] = meta\n",
    "\n",
    "X_train, y_train = translate_to_dataset(train_dfs)\n",
    "X_val, y_val = translate_to_dataset(val_dfs, meta)\n",
    "X_test, y_test = translate_to_dataset(test_dfs, meta)\n",
    "\n",
    "print(\"X_train, y_train shape: \", X_train.shape, y_train.shape)\n",
    "print(\"X_val, y_val shape: \", X_val.shape, y_val.shape)\n",
    "print(\"X_test, y_test shape: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21477b-f15a-4125-a74f-ed4e9100213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "root_dir = (\n",
    "    hyper_params[\"root_dir\"] + \"/\" + hyper_params[\"name\"] + hyper_params[\"version\"]\n",
    ")\n",
    "\n",
    "create_folder(root_dir + \"/\" + hyper_params[\"dirs\"][\"weights\"])\n",
    "create_folder(root_dir + \"/\" + hyper_params[\"dirs\"][\"history\"])\n",
    "create_folder(root_dir + \"/\" + hyper_params[\"dirs\"][\"predict\"])\n",
    "create_folder(root_dir + \"/\" + hyper_params[\"dirs\"][\"model\"])\n",
    "create_folder(root_dir + \"/\" + hyper_params[\"dirs\"][\"metric\"])\n",
    "\n",
    "with open(f\"{root_dir}/config.json\", \"w\") as outfile:\n",
    "    json.dump(hyper_params, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba958c-bb6a-44ca-9092-cdb23eec8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=5, mode=\"min\", verbose=1, min_lr=1e-6\n",
    ")\n",
    "ely_cb = EarlyStopping(monitor=\"val_loss\", patience=15, mode=\"min\", verbose=1)\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=root_dir\n",
    "    + \"/\"\n",
    "    + hyper_params[\"dirs\"][\"weights\"]\n",
    "    + \"/e{epoch:02d}-v{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    period=1,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9c2f5-a0d9-4428-81b3-0c67a27470ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling1D,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling1D,\n",
    "    Attention,\n",
    "    Permute,\n",
    ")\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    \n",
    "    a = Permute((2, 1))(inputs) # same transpose\n",
    "    a = Dense(inputs.shape[1], activation='softmax')(a)\n",
    "    \n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    output_attention_mul  = tf.keras.layers.multiply([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "def build_model(inputs):\n",
    "    input_tensor = Input(shape=(inputs.shape[1], inputs.shape[2]), name=\"input\")\n",
    "\n",
    "    x = Conv1D(256, kernel_size=3, kernel_initializer='he_uniform', activation='relu', strides=1, padding=\"valid\")(input_tensor)\n",
    "    # x = Conv1D(128, kernel_size=3, activation='relu', strides=1, padding=\"valid\")(x)\n",
    "    # x = GRU(\n",
    "    #     units=256,\n",
    "    #     activation=\"tanh\",\n",
    "    #     kernel_initializer=\"glorot_uniform\",\n",
    "    #     return_sequences=True,\n",
    "    # )(input_tensor)\n",
    "    # x = GRU(\n",
    "    #     units=160,\n",
    "    #     activation=\"tanh\",\n",
    "    #     kernel_initializer=\"he_uniform\",\n",
    "    #     return_sequences=True,\n",
    "    # )(x)\n",
    "    # x = attention_3d_block(x)\n",
    "    x = MaxPooling1D(pool_size=3, strides=1)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, kernel_initializer='he_uniform', activation=LeakyReLU(0.25))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(y_train.shape[2], kernel_initializer='he_uniform', activation=\"relu\", name=\"output\")(x)\n",
    "\n",
    "    _model = Model(\n",
    "        inputs=input_tensor,\n",
    "        outputs=output,\n",
    "        name=f'{hyper_params[\"name\"].lower()}_v{hyper_params[\"version\"]}',\n",
    "    )\n",
    "\n",
    "    _model.compile(\n",
    "        optimizer=Adam(learning_rate=hyper_params[\"model\"][\"lr\"]),\n",
    "        loss=hyper_params[\"model\"][\"loss\"].lower(),\n",
    "        metrics=RootMeanSquaredError(),\n",
    "    )\n",
    "\n",
    "    return _model\n",
    "\n",
    "\n",
    "model = build_model(X_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b2afe-1abb-47dc-898e-dcbc23d2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    training_res = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=hyper_params[\"model\"][\"epochs\"],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[rlr_cb, ely_cb, mcp_cb],\n",
    "    )\n",
    "    pd.DataFrame(training_res.history).to_csv(\n",
    "        root_dir + \"/\" + hyper_params[\"dirs\"][\"history\"] + \"/history.csv\", index=False\n",
    "    )\n",
    "    plt.figure(figsize=(28, 10))\n",
    "    plt.plot(training_res.history[\"loss\"], \"o--\", label=\"train\")\n",
    "    plt.plot(training_res.history[\"val_loss\"], \"o--\", label=\"valid\")\n",
    "    plt.xlabel(\"Epochs\", fontsize=15)\n",
    "    plt.ylabel(\"Loss - RMSE\", fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674e370-5426-4ce4-bbcd-1388fa112df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"project/Conv/Conv_Weather04/result/model/conv_weather_04.h5\")\n",
    "train_res = get_result_df(model, train_dfs, meta)\n",
    "train_res['TYPE'] = 'train'\n",
    "val_res = get_result_df(model, val_dfs, meta)\n",
    "val_res['TYPE'] = 'val'\n",
    "test_res = get_result_df(model, test_dfs, meta)\n",
    "test_res['TYPE'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c4dc-b7ea-485a-8aaf-3eccef3dcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.load_weights('project/GRU/GRU09/training/weights/e23-v17.85.h5')\n",
    "# model = tf.keras.models.load_model(\"project/GRU/GRUkt01/result/model/gru_kt01.h5\")\n",
    "# train_res = get_result_df(model, train_dfs, meta)\n",
    "# val_res = get_result_df(model, val_dfs, meta)\n",
    "# test_res = get_result_df(model, test_dfs, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfb840-4cb0-40d6-8932-1b5471128677",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(train_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e556433-8039-4949-85df-952c05785eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(val_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415855fa-4aa7-453a-89ca-a5cb3d3a0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(test_res, ['PM2.5_PRED', 'PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT', 'PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bc8bd-1ec6-4a52-923d-39745b8265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = val_res.plot.scatter(x=\"PM2.5\", y=\"PM2.5_PRED\", c=\"y\", figsize=(15, 15))\n",
    "test_res.plot.scatter(x=\"PM2.5\", y=\"PM2.5_PRED\", c=\"g\", figsize=(15, 15), ax=ax)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "\n",
    "ax.plot(lims, lims, \"r-\", linewidth=2, alpha=0.75, zorder=2)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68b24f-dcc0-4760-bbfb-5f6b56d05284",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "cols = [\"pm1\", \"pm2.5\", \"pm10\"]\n",
    "total_res = pd.concat([train_res, val_res, test_res])\n",
    "res_dfs = [total_res, train_res, val_res, test_res]\n",
    "res_indices = [\"Total\", \"Train\", \"Validation\", \"Test\"]\n",
    "metrics = [calc_r2, calc_corrcoef, calc_nmse, calc_fb, calc_b, calc_a_div_co]\n",
    "metrics_indices = [\"R Square\", \"Corr\", \"NMSE\", \"FB\", \"B\", \"a/C\"]\n",
    "\n",
    "\n",
    "def calc_metric(_f, _df, _col):\n",
    "    return _f(_df[_col].values, _df[_col + \"_PRED\"].values)\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"======== {col} prediction results ========\")\n",
    "    res_dict = {\n",
    "        \"Metric\": metrics_indices,\n",
    "        \"Total\": [],\n",
    "        \"Train\": [],\n",
    "        \"Validation\": [],\n",
    "        \"Test\": [],\n",
    "    }\n",
    "\n",
    "    for j, m in enumerate(metrics):\n",
    "        for i, rd in enumerate(res_dfs):\n",
    "            s = calc_metric(m, rd, col.upper())\n",
    "            res_dict[res_indices[i]].append(s)\n",
    "\n",
    "    r_df = pd.DataFrame(res_dict)\n",
    "    print(r_df)\n",
    "    print()\n",
    "    if save:\n",
    "        r_df.to_csv(\n",
    "            f'{root_dir}/{hyper_params[\"dirs\"][\"metric\"]}/result_{col}.csv',\n",
    "            index=False,\n",
    "            float_format=\"%.3f\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe65902-ca3d-457f-ae34-1f419fca475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    total_res.to_csv(\n",
    "        root_dir + \"/\" + hyper_params[\"dirs\"][\"predict\"] + \"/predict.csv\",\n",
    "        index_label=\"DATE\",\n",
    "    )\n",
    "\n",
    "    model.save(\n",
    "        root_dir\n",
    "        + \"/\"\n",
    "        + hyper_params[\"dirs\"][\"model\"]\n",
    "        + f'/{hyper_params[\"name\"].lower()}_{hyper_params[\"version\"]}.h5'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
