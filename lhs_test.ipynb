{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fa439a-7396-4ddc-80d5-81a775ec3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import lhs\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b61dd5-8712-4277-a6a5-e156f8621785",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = [\"PM1\", \"PM2.5\", \"PM10\"]\n",
    "FEATURE_LABEL = [\n",
    "    \"PM1_2.5_OUT\",\n",
    "    \"PM1_2.5_H_OUT\",\n",
    "    \"PM2.5_OUT\",\n",
    "    \"PM2.5_H_OUT\",\n",
    "    \"PM2.5_10_OUT\",\n",
    "    \"PM2.5_10_H_OUT\",\n",
    "    \"PERSON_NUMBER\",\n",
    "    \"AIR_PURIFIER\",\n",
    "    \"WINDOW\",\n",
    "    \"AIR_CONDITIONER\",\n",
    "    \"DOOR\",\n",
    "    \"TEMPERATURE\",\n",
    "    \"WIND_SPEED\",\n",
    "    \"WIND_DEG\",\n",
    "    \"HUMIDITY\",\n",
    "]\n",
    "\n",
    "NON_ACTIVITY = [\n",
    "    \"PERSON_NUMBER\",\n",
    "    \"PM2.5_OUT\",\n",
    "    \"PM2.5_H_OUT\",\n",
    "    \"PM1_2.5_OUT\",\n",
    "    \"PM1_2.5_H_OUT\",\n",
    "    \"PM2.5_10_OUT\",\n",
    "    \"PM2.5_10_H_OUT\",\n",
    "    \"PM1_OUT\",\n",
    "    \"PM1_H_OUT\",\n",
    "    \"PM10_OUT\",\n",
    "    \"PM10_H_OUT\",\n",
    "    \"TEMPERATURE\",\n",
    "    \"WIND_SPEED\",\n",
    "    \"WIND_DEG\",\n",
    "    \"HUMIDITY\",\n",
    "]\n",
    "\n",
    "ACTIVITY = [x for x in FEATURE_LABEL if x not in NON_ACTIVITY]\n",
    "\n",
    "used_data = [\n",
    "    {\"start\": \"2022-05-07 09:40\", \"end\": \"2022-05-17 08:38\"},\n",
    "    {\"start\": \"2022-05-17 11:25\", \"end\": \"2022-05-30 23:26\"},\n",
    "    {\"start\": \"2022-06-01 22:40\", \"end\": \"2022-07-02 07:00\"},\n",
    "    {\"start\": \"2022-07-02 16:40\", \"end\": \"2022-07-09 07:13\"},\n",
    "    {\"start\": \"2022-07-09 14:30\", \"end\": \"2022-07-12 10:00\"},\n",
    "    {\"start\": \"2022-07-25 12:00\", \"end\": \"2022-08-01 10:00\"},\n",
    "    {\"start\": \"2022-08-03 09:00\", \"end\": \"2022-08-11 22:18\"},\n",
    "    {\"start\": \"2022-08-12 12:14\", \"end\": \"2022-08-20 00:00\"},\n",
    "]\n",
    "\n",
    "moving_average_window = 15\n",
    "moving_average_method = 'median'\n",
    "val_size = 0.15\n",
    "test_size = 0.25\n",
    "train_size = 1 - val_size - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e332219-0487-4598-a393-ffadd0037d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('../data/weather.csv', index_col='DATE', parse_dates=True)[['TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']]\n",
    "weather_df['WIND_DEG'] = np.sin(weather_df['WIND_DEG'].values * np.pi / 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29aad361-318d-403a-aa86-e35e5a88ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excludes: ['PERSON_NUMBER', 'AIR_PURIFIER', 'WINDOW', 'DOOR', 'AIR_CONDITIONER']\n",
      "includes: ['PM1', 'PM2.5', 'PM10', 'PM1_OUT', 'PM2.5_OUT', 'PM10_OUT', 'PM1_H_OUT', 'PM2.5_H_OUT', 'PM10_H_OUT', 'PM1_2.5', 'PM2.5_10', 'PM1_2.5_OUT', 'PM1_2.5_H_OUT', 'PM2.5_10_OUT', 'PM2.5_10_H_OUT', 'TEMPERATURE', 'WIND_DEG', 'WIND_SPEED', 'HUMIDITY']\n"
     ]
    }
   ],
   "source": [
    "df_org = load_pm(\"../data/data.csv\")\n",
    "add_diff(df_org)\n",
    "\n",
    "df = apply_moving_average(\n",
    "    pd.concat([df_org, weather_df], axis=1), 'mean', moving_average_window, True\n",
    ")\n",
    "df[['PERSON_NUMBER', 'AIR_PURIFIER', 'AIR_CONDITIONER', 'WINDOW', 'DOOR']].fillna(method='ffill')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "dfs = trim_df(df, used_data)\n",
    "train_dfs, val_dfs, test_dfs = train_test_split_df(dfs, val_size, test_size)\n",
    "meta = get_meta(train_dfs, NON_ACTIVITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56520655-2665-4982-a78d-1531c991aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = df[(df.index >= pd.to_datetime('2022-07-09 23:00')) & (df.index <= pd.to_datetime('2022-07-12'))].resample('T').first().fillna(value=np.nan).plot(kind='line', y=['PM2.5', 'PM2.5_OUT', 'PM2.5_H_OUT'], figsize=(18, 12), fontsize=17)\n",
    "# ax.set_ylabel('PM2.5 $\\mu g m^3$', fontsize=17)\n",
    "# ax.set_xlabel('Date', fontsize=17)\n",
    "# ax.legend(fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041b523d-c1d2-4eee-8c55-f3157a72a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_params = {\n",
    "    \"window_size\": [5, 12, 16, 30, 60],\n",
    "    \"pool_size\": [x for x in range(2, 6)],\n",
    "    \"pool_strides\": [x for x in range(1, 4)],\n",
    "    \"dense\": {\n",
    "        \"units\": [x*32+16 for x in range(8)],\n",
    "        \"dropout\": np.arange(0, 0.5+0.05, 0.05),\n",
    "        \"leaky_relu\": np.arange(0, 0.5+0.05, 0.05),\n",
    "    },\n",
    "    \"batch_size\": [x*32+32 for x in range(8)],\n",
    "    \"lr\": [0.001, 0.0001, 0.00001],\n",
    "}\n",
    "\n",
    "conv_params = {\n",
    "    \"conv_0\": {\n",
    "        \"filters\": [x*32+16 for x in range(8)],\n",
    "        \"kernel_size\": [x*2+3 for x in range(3)],\n",
    "        \"strides\": [x+1 for x in range(3)],\n",
    "    },\n",
    "    \"conv_1\": {\n",
    "        \"filters\": [None]+[x*32+16 for x in range(8)],\n",
    "        \"kernel_size\": [x*2+3 for x in range(3)],\n",
    "        \"strides\": [x+1 for x in range(3)],\n",
    "    },\n",
    "}\n",
    "\n",
    "rnn_params = {\n",
    "    \"conv_0\": {\n",
    "        \"activated\": [True, False],\n",
    "        \"filters\": [None]+[x*32+16 for x in range(8)],\n",
    "        \"kernel_size\": [x*2+3 for x in range(3)],\n",
    "        \"strides\": [x+1 for x in range(3)],\n",
    "    },\n",
    "    \"rnn_0\": {\n",
    "        \"layer\": ['naive', 'lstm', 'gru'],\n",
    "        \"units\": [x*32+16 for x in range(8)],\n",
    "        \"dropout\": np.arange(0, 0.5+0.05, 0.05),\n",
    "    },\n",
    "    \"rnn_1\": {\n",
    "        \"layer\": ['naive', 'lstm', 'gru'],\n",
    "        \"units\": [None]+[x*32+16 for x in range(8)],\n",
    "        \"dropout\": np.arange(0, 0.5+0.05, 0.05),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731ac9fe-faaa-4c86-a49b-e8b1a4150e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = {}\n",
    "val_ds = {}\n",
    "test_ds = {}\n",
    "for win in basic_params[\"window_size\"]:\n",
    "    train_ds[str(win)] = translate_to_dataset(train_dfs, FEATURE_LABEL, TARGET_LABEL, win, 1, 0, NON_ACTIVITY, scale=True, verbose=False, _meta=meta)\n",
    "    val_ds[str(win)] = translate_to_dataset(val_dfs, FEATURE_LABEL, TARGET_LABEL, win, 1, 0, NON_ACTIVITY, scale=True, verbose=False, _meta=meta)\n",
    "    test_ds[str(win)] = translate_to_dataset(test_dfs, FEATURE_LABEL, TARGET_LABEL, win, 1, 0, NON_ACTIVITY, scale=True, verbose=False, _meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d6aaba-ae18-4dc6-a5ba-0a7947f5e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_len(param):\n",
    "    l = 0\n",
    "    for p in param.keys():\n",
    "        if type(param[p]) == dict:\n",
    "            l += get_param_len(param[p])\n",
    "        else:\n",
    "            l += 1\n",
    "    return l\n",
    "\n",
    "def get_param_len_list(param):\n",
    "    li = []\n",
    "    for p in param.keys():\n",
    "        if type(param[p]) == dict:\n",
    "            li += get_param_len_list(param[p])\n",
    "        else:\n",
    "            li.append(len(param[p]))\n",
    "    return li\n",
    "\n",
    "def get_param_keys(param):\n",
    "    keys = []\n",
    "    for p in param.keys():\n",
    "        if type(param[p]) == dict:\n",
    "            keys += get_param_len_list(param[p])\n",
    "        else:\n",
    "            keys.append(p)\n",
    "    return keys\n",
    "\n",
    "def get_samples(param, n_samples):\n",
    "    n_dim = get_param_len(basic_params) + get_param_len(param)\n",
    "    return lhs(n_dim, n_samples, 'maximin')\n",
    "\n",
    "def smp_to_indices(sample, param):\n",
    "    len_list = get_param_len_list(basic_params) + get_param_len_list(param)\n",
    "    smp_cpy = np.zeros(sample.shape)\n",
    "    if len(len_list) != sample.shape[1]:\n",
    "        print('[ERROR] invalid shape')\n",
    "        return\n",
    "    for i, ll in enumerate(len_list):\n",
    "        smp_cpy[:, i] = np.floor(sample[:, i] * ll)\n",
    "    smp_cpy = np.int32(smp_cpy)\n",
    "    return smp_cpy\n",
    "\n",
    "def dict_cat(param):\n",
    "    new_param = {}\n",
    "    for key in basic_params.keys():\n",
    "        new_param[key] = basic_params[key]\n",
    "    for key in param.keys():\n",
    "        new_param[key] = param[key]\n",
    "    return new_param\n",
    "\n",
    "def get_smp_values(param, _indices):\n",
    "    val_dict = {}\n",
    "    param = dict_cat(param)\n",
    "    val_list = get_param_len_list(param)\n",
    "    i = 0\n",
    "    for p in param.keys():\n",
    "        if type(param[p]) == dict:\n",
    "            val_dict[p] = {}\n",
    "            for p2 in param[p].keys():\n",
    "                val_dict[p][p2] = param[p][p2][_indices[i]]\n",
    "                i += 1\n",
    "        else:\n",
    "            val_dict[p] = param[p][_indices[i]]\n",
    "            i += 1\n",
    "    return val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c186ccd0-a295-49c9-a872-b13dc7d8d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_smp = get_samples(conv_params, 1024)\n",
    "# conv_idc = smp_to_indices(conv_smp, conv_params)\n",
    "\n",
    "# rnn_smp = get_samples(rnn_params, 1024)\n",
    "# rnn_idc = smp_to_indices(rnn_smp, rnn_params)\n",
    "\n",
    "conv_idc = np.load('lhs_opt/2022-08-23_17:10/conv_idc.npy')\n",
    "rnn_idc = np.load('lhs_opt/2022-08-23_17:10/rnn_idc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a975410a-0605-46d3-9f7f-cf9a293b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('lhs_opt/2022-08-23_17:10/conv_idc.npy', conv_idc)\n",
    "# np.save('lhs_opt/2022-08-23_17:10/rnn_idc.npy', rnn_idc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d471f3-2957-4a14-a2ed-cda62f6b29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "# proj_name = dt.datetime.strftime(dt.datetime.now(), '%Y-%m-%d_%H:%M')\n",
    "# create_folder('lhs_opt/'+proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337f9ac4-aaa8-467f-9008-3b2d32fe5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    SimpleRNN,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_conv_layer(param, _input):\n",
    "    x = _input\n",
    "    for p in param.keys():\n",
    "        info = str(p).split('_')\n",
    "        layer_type = info[0]\n",
    "        if layer_type == 'conv' and param[p][\"filters\"] is not None:\n",
    "            f = param[p][\"filters\"]\n",
    "            k = param[p][\"kernel_size\"]\n",
    "            s = param[p][\"strides\"]\n",
    "            x = Conv1D(f, kernel_size=k, kernel_initializer='he_uniform', activation='relu', strides=s, padding='same')(x)\n",
    "    return x\n",
    "\n",
    "def build_rnn_layer(param, _input):\n",
    "    x = _input\n",
    "    for p in param.keys():\n",
    "        info = str(p).split('_')\n",
    "        layer_type = info[0]\n",
    "        num_type = int(info[1])\n",
    "        if layer_type == 'conv' and param[p][\"activated\"]:\n",
    "            f = param[p][\"filters\"]\n",
    "            k = param[p][\"kernel_size\"]\n",
    "            s = param[p][\"strides\"]\n",
    "            i += 3\n",
    "            x = Conv1D(f, kernel_size=k, kernel_initializer='he_uniform', activation='relu', strides=s, padding='same')(x)\n",
    "        elif layer_type == 'rnn':\n",
    "            layer = param[p][\"layer\"]\n",
    "            units = param[p][\"units\"]\n",
    "            dropout = param[p][\"dropout\"]\n",
    "            if layer == 'naive':\n",
    "                x = SimpleRNN(units=units, \n",
    "                              dropout=dropout,\n",
    "                              activation='tanh', \n",
    "                              kernel_initializer='glorot_uniform', \n",
    "                              return_sequences=True,\n",
    "                             )(x)\n",
    "            elif layer == 'lstm':\n",
    "                x = LSTM(units=units,\n",
    "                         dropout=dropout,\n",
    "                         activation='tanh', \n",
    "                         kernel_initializer='glorot_uniform', \n",
    "                         return_sequences=True,\n",
    "                        )(x)\n",
    "            elif layer == 'gru':\n",
    "                x = GRU(units=units, \n",
    "                        dropout=dropout,\n",
    "                        activation='tanh', \n",
    "                        kernel_initializer='glorot_uniform', \n",
    "                        return_sequences=True,\n",
    "                       )(x)\n",
    "    return x\n",
    "\n",
    "def model_builder(p, input_shape, output_size, layer_type='conv'):\n",
    "    input_tensor = Input(shape=input_shape, name=\"input\")\n",
    "    x = input_tensor\n",
    "    if layer_type == 'conv':\n",
    "        x = build_conv_layer(p, x)\n",
    "    elif layer_type == 'rnn':\n",
    "        x = build_rnn_layer(p, x)\n",
    "    \n",
    "    x = MaxPooling1D(pool_size=p[\"pool_size\"], strides=p[\"pool_strides\"], padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(p[\"dense\"][\"units\"], kernel_initializer='he_uniform', activation=LeakyReLU(p[\"dense\"][\"leaky_relu\"]))(x)\n",
    "    x = Dropout(p[\"dense\"][\"dropout\"])(x)\n",
    "    output = Dense(output_size, kernel_initializer='he_uniform', activation=\"relu\", name=\"output\")(x)\n",
    "\n",
    "    _model = Model(\n",
    "        inputs=input_tensor,\n",
    "        outputs=output,\n",
    "        name='test',\n",
    "    )\n",
    "\n",
    "    _model.compile(\n",
    "        optimizer=Adam(learning_rate=p[\"lr\"]),\n",
    "        loss='mse',\n",
    "        metrics=RootMeanSquaredError(),\n",
    "    )\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa0b5d9-9620-4d57-a756-b9fc6adb7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    if tf.__version__[0] == '2':\n",
    "        tf.random.set_seed(3)\n",
    "    else:\n",
    "        tf.set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ad25bd-5f68-4b8e-8fb7-06abdfc76e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=5, mode=\"min\", min_lr=1e-6, verbose=False\n",
    ")\n",
    "ely_cb = EarlyStopping(monitor=\"val_loss\", patience=15, mode=\"min\", verbose=False, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbadd1e4-f235-4bd8-8f66-2966b5484641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def calc_metric(real, pred):\n",
    "    metrics = [calc_r2, calc_corrcoef, calc_nmse, calc_fb, calc_b, calc_a_div_co, calc_mse]\n",
    "    res = np.zeros(len(metrics))\n",
    "    metrics_indices = [\"R Square\", \"Corr\", \"NMSE\", \"FB\", \"B\", \"a/C\"]\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        print(metrics_indices[i])\n",
    "        res[i] = metric(real, pred)\n",
    "    return res\n",
    "\n",
    "def optimize_params(param, idc, proj_dir):\n",
    "    metric_df = pd.DataFrame(np.zeros((len(idc), get_param_len(param))), columns=['r2', 'corr', 'nmse', 'fb', 'b', 'a/c'])\n",
    "    for i, conv_idx in enumerate(idc):\n",
    "        reset_seeds()\n",
    "        root_dir = proj_dir+f'/trial{i:03d}'\n",
    "        create_folder(root_dir, ignore_exist=True)\n",
    "        param_values = get_smp_values(param, conv_idx)\n",
    "        print(f'[INFO] Trial{i:03d} training start')\n",
    "        with open(f\"{root_dir}/params.json\", \"w\") as outfile:\n",
    "            json.dump(param_values, outfile)\n",
    "            outfile.close()\n",
    "        X_train = train_ds[str(param_values[\"window_size\"])][0]\n",
    "        y_train = train_ds[str(param_values[\"window_size\"])][1].reshape(-1, 3)\n",
    "        X_val = val_ds[str(param_values[\"window_size\"])][0]\n",
    "        y_val = val_ds[str(param_values[\"window_size\"])][1].reshape(-1, 3)\n",
    "        X_test = test_ds[str(param_values[\"window_size\"])][0]\n",
    "        y_test = test_ds[str(param_values[\"window_size\"])][1].reshape(-1, 3)\n",
    "\n",
    "        model = model_builder(param_values, X_train[0].shape, y_train.shape[1])\n",
    "\n",
    "        with tf.device(\"/device:GPU:0\"):\n",
    "            history = model.fit(\n",
    "                x=X_train,\n",
    "                y=y_train,\n",
    "                batch_size=param_values[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "                epochs=100,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[rlr_cb, ely_cb],\n",
    "                verbose=False,\n",
    "            )\n",
    "            pd.DataFrame(history.history).to_csv(root_dir+'/history.csv', index=False)\n",
    "            print(f'[INFO] Trial{i:03d} finished training')\n",
    "\n",
    "            y_hat = model.predict(X_test)\n",
    "            print(f'[INFO] Trial{i:03d} finished predict')\n",
    "            metric = calc_metric(y_test, y_hat)\n",
    "            metric_df.iloc[i] = metric\n",
    "            metric_df.to_csv(f'{proj_dir}/metric.csv', index_label='index')\n",
    "            print(f'[INFO] Trial{i:03d} successfully ended.. Clear session')\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        del model\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b8580ad-3735-4630-93ea-5b9026dbf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_params(conv_params, conv_idc[:128], 'lhs_opt/2022-08-23_17:10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0591400-7731-4d74-926a-88d449f529ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder in `lhs_opt/2022-08-23_17:10/trial000`\n",
      "[INFO] Trial000 training start\n",
      "[INFO] Finished training\n",
      "29994/29994 [==============================] - 29s 959us/step\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_model(param, _model):\n",
    "    X_train = train_ds[str(param[\"window_size\"])][0]\n",
    "    y_train = train_ds[str(param[\"window_size\"])][1].reshape(-1, 3)\n",
    "    X_val = val_ds[str(param[\"window_size\"])][0]\n",
    "    y_val = val_ds[str(param[\"window_size\"])][1].reshape(-1, 3)\n",
    "    \n",
    "    history = _model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=param_values[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[rlr_cb, ely_cb],\n",
    "        verbose=False,\n",
    "    )\n",
    "    pd.DataFrame(history.history).to_csv(root_dir+'/history.csv', index=False)\n",
    "    print(f'[INFO] Finished training')\n",
    "    K.clear_session()\n",
    "\n",
    "idc = conv_idc[:128]\n",
    "param = conv_params\n",
    "proj_dir = 'lhs_opt/2022-08-23_17:10'\n",
    "metric_df = pd.DataFrame(np.zeros((len(idc), get_param_len(param))), columns=['r2', 'corr', 'nmse', 'fb', 'b', 'a/c'])\n",
    "for i, conv_idx in enumerate(idc):\n",
    "    reset_seeds()\n",
    "    root_dir = proj_dir+f'/trial{i:03d}'\n",
    "    create_folder(root_dir, ignore_exist=True)\n",
    "    param_values = get_smp_values(param, conv_idx)\n",
    "    print(f'[INFO] Trial{i:03d} training start')\n",
    "    with open(f\"{root_dir}/params.json\", \"w\") as outfile:\n",
    "        json.dump(param_values, outfile)\n",
    "        outfile.close()\n",
    "        \n",
    "    X_test = test_ds[str(param_values[\"window_size\"])][0]\n",
    "    y_test = test_ds[str(param_values[\"window_size\"])][1].reshape(-1, 3)\n",
    "\n",
    "    model = model_builder(param_values, X_test[0].shape, y_test.shape[1])\n",
    "    train_model(param_values, model)\n",
    "\n",
    "    y_hat = model.predict(X_test, batch_size=1)\n",
    "    print(f'[INFO] Trial{i:03d} finished predict')\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    print(f'[INFO] Trial{i:03d} successfully ended.. Clear session')\n",
    "    metric = calc_metric(y_test, y_hat)\n",
    "    print(f'[INFO] Trial{i:03d} calculated metrics')\n",
    "    metric_df.iloc[i] = metric\n",
    "    metric_df.to_csv(f'{proj_dir}/metric.csv', index_label='index')\n",
    "    print(f'[INFO] Trial{i:03d} successfully saved metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b9db6a8e-6c55-4c15-afd0-2bd618762f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiheo/.conda/envs/jiheo/lib/python3.9/site-packages/numpy/lib/function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>corr</th>\n",
       "      <th>nmse</th>\n",
       "      <th>fb</th>\n",
       "      <th>b</th>\n",
       "      <th>a/c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.234757</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.826999</td>\n",
       "      <td>0.447484</td>\n",
       "      <td>0.086904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.276910</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856268</td>\n",
       "      <td>0.341585</td>\n",
       "      <td>0.159765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.315153</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.456213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.300174</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.039599</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.433191</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>-0.234900</td>\n",
       "      <td>0.643407</td>\n",
       "      <td>0.095825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.583454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.160986</td>\n",
       "      <td>0.715055</td>\n",
       "      <td>0.148432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.772793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.961168</td>\n",
       "      <td>0.877114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               r2        corr        nmse          fb           b         a/c\n",
       "count  128.000000  128.000000  128.000000  128.000000  128.000000  128.000000\n",
       "mean    -1.234757    0.999987         inf   -0.826999    0.447484    0.086904\n",
       "std      2.276910    0.000031         NaN    0.856268    0.341585    0.159765\n",
       "min     -4.315153    0.999911    0.018420   -2.000000    0.000000   -0.456213\n",
       "25%     -4.300174    0.999996    0.039599   -2.000000    0.000000    0.000000\n",
       "50%      0.433191    0.999999    0.057279   -0.234900    0.643407    0.095825\n",
       "75%      0.583454    1.000000         NaN   -0.160986    0.715055    0.148432\n",
       "max      0.772793    1.000000         inf    0.024952    0.961168    0.877114"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('lhs_opt/2022-08-24_11:38/metric.csv', index_col='index').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439a744-aaef-41ba-ab96-f1e385239cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
